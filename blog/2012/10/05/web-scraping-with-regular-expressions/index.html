
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Web Scraping with Regular Expressions - Michael Herman</title>
  <meta name="author" content="Michael Herman">

  
  <meta name="description" content="Problem:You need to extract and parse all the headers and links from a web site or an XML feed, and then dump the data into a CSV file. Import &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://mjhea0.github.com/blog/2012/10/05/web-scraping-with-regular-expressions/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Michael Herman" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37074204-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Michael Herman</a></h1>
  
    <h2>get more from your data</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  

<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:mjhea0.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>

  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/youtube-tutorials">Youtube</a></li>
</ul>
</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Web Scraping With Regular Expressions</h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-10-05T13:26:00-07:00" pubdate data-updated="true">Oct 5<span>th</span>, 2012</time>
        
      </p>
    
  </header>


<div class="entry-content"><p><strong>Problem:</strong>You need to extract and parse all the headers and links from a web site or an XML feed, and then dump the data into a CSV file.</p>

<p><strong>Import modules:</strong></p>

<pre><code>import csv
from urllib import urlopen
import re`
</code></pre>

<p><strong>Perform html/xml query, grab desired fields, create a range:</strong></p>

<pre><code>xml = urlopen("http://www.tableausoftware.com/public/feed.rss").read()

xmlTitle = re.compile("&amp;lt;title&amp;gt;(.*)&amp;lt;/title&amp;gt;")
xmlLink = re.compile("&amp;lt;link&amp;gt;(.*)&amp;lt;/link&amp;gt;")

findTitle = re.findall(xmlTitle,xml)
findLink = re.findall(xmlLink,xml)

iterate = []
iterate[:] = range(1, 25)
</code></pre>

<p><strong>Open CSV file:</strong></p>

<pre><code>writer = csv.writer(open("pytest.csv", "wb"))
</code></pre>

<p><strong>Write header to CSV file (you want to do this before you enter the loop):</strong></p>

<pre><code>head = ("Title", "URL")
writer.writerow(head)
</code></pre>

<p><strong>Write the For loop to iterate through the XML file and write the rows to the CSV file:</strong></p>

<pre><code>for i in iterate:
    writer.writerow([findTitle[i], findLink[i]])
</code></pre>

<p><strong><em>Final Script:</em></strong></p>

<pre><code>#!/usr/bin/env python

import csv
from urllib import urlopen
import re

# Open and read HTMl / XML
xml = urlopen("http://www.tableausoftware.com/public/feed.rss").read()

# Grab article titles and links using regex
xmlTitle = re.compile("&amp;lt;title&amp;gt;(.*)&amp;lt;/title&amp;gt;")
xmlLink = re.compile("&amp;lt;link&amp;gt;(.*)&amp;lt;/link&amp;gt;")

# Find and store the data
findTitle = re.findall(xmlTitle,xml)
findLink = re.findall(xmlLink,xml)

#Iterate through the articles to create a range
iterate = []
iterate[:] = range(1, 25)

# Open the CSV file, write the headers
writer = csv.writer(open("pytest.csv", "wb"))
head = ("Title", "URL")
writer.writerow(head)

# Using a For Loop, write the results to the CSV file, row by row
for i in iterate:
    writer.writerow([findTitle[i], findLink[i]])
</code></pre>

<hr />

<div class="embed-video-container"><iframe src="http://www.youtube.com/embed/DcZTNwdWVeo "></iframe></div>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Michael Herman</span></span>

      








  


<time datetime="2012-10-05T13:26:00-07:00" pubdate data-updated="true">Oct 5<span>th</span>, 2012</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/python/'>python</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://mjhea0.github.com/blog/2012/10/05/web-scraping-with-regular-expressions/" data-via="" data-counturl="http://mjhea0.github.com/blog/2012/10/05/web-scraping-with-regular-expressions/" >Tweet</a>
  
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2012/09/30/import-data-from-excel-into-mysql-using-python/" title="Previous Post: Import data from Excel into MySQL using Python">&laquo; Import data from Excel into MySQL using Python</a>
      
      
        <a class="basic-alignment right" href="/blog/2012/10/06/differentiating-between-bounce-rates/" title="Next Post: Differentiating Between Bounce Rates">Differentiating Between Bounce Rates &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
	<br />
	<a class="sitelink" href="https://twitter.com/mikeherman" target="_blank"><img class="icon" src="https://raw.github.com/mjhea0/mjhea0.github.com/master/images/social/24px/twitter.png"/></a>
	<a href="http://www.linkedin.com/pub/michael-herman/3b/a94/4" target="_blank"><img alt="" src="https://raw.github.com/mjhea0/mjhea0.github.com/master/images/social/24px/linkedin.png"/></a>
	<a href="http://bit.ly/TzGt2K" target="_blank"><img alt="" src="https://raw.github.com/mjhea0/mjhea0.github.com/master/images/social/24px/youtube.png"/></a>
	<a href="https://github.com/mjhea0" target="_blank"><img alt="" src="https://raw.github.com/mjhea0/mjhea0.github.com/master/images/social/24px/github.png"/></a>
	
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/12/30/django-basics/">Django Basics - Installing Django and Setting up a Project and App</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/12/excel-tips-how-to-cut-down-on-calculations-using-sumif-and-sumifs/">Excel Tips: How to Cut Down on Calculations Using SUMIF and SUMIFS</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/10/crash-course-in-web2py-part-5-modifying-the-appearance-and-deploying-the-web-form/">Crash Course in web2py (part 5 - modifying the appearance and deploying the web form)</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/09/crash-course-in-web2py-part-4-managing-form-records/">Crash Course in web2py (part 4 - managing form records)</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/06/crash-course-in-web2py-part-3-form-validation/">Crash Course in web2py (part 3 - form validation)</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>
  <ul id="categories">
    <li class='category'><a href='/blog/categories/analytics/'>analytics (5)</a></li>
<li class='category'><a href='/blog/categories/excel/'>excel (3)</a></li>
<li class='category'><a href='/blog/categories/python/'>python (9)</a></li>

  </ul>
</section><section>

</section>







  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Michael Herman &copy; 2012 -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span> -
  <a href="https://github.com/mjhea0/mjhea0.github.com">Fork me on Github</a>

</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
