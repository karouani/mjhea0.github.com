
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Michael Herman</title>
  <meta name="author" content="Michael Herman">

  
  <meta name="description" content="Excel 2013 promises greater functionality and the ability to more quickly input and analyze data. Although this version of Excel uses some of the &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://mjhea0.github.com/blog/page/4/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Michael Herman" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-37074204-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Michael Herman</a></h1>
  
    <h2>get more from your data</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  

<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:mjhea0.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>

  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/youtube-tutorials">Youtube</a></li>
</ul>
</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/11/09/51-new-excel-2013-functions/">51 New Excel 2013 Functions</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-11-09T15:50:00-08:00" pubdate data-updated="true">Nov 9<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>Excel 2013 promises greater functionality and the ability to more quickly input and analyze data. Although this version of Excel uses some of the same functions as older versions, you should learn the 51 new functions to make sure you don&#8217;t miss out on something that could become a favorite resource. In addition, some older functions may become obsolete as Microsoft continues to create updated versions of Excel. Check out the latest Office has to offer with the following new functions.</em></p>

<p><em>You can also download an XLSX version <a href="http://backwardsteps.com/tutorials/excel%202013%20functions.xlsx">here</a>, comparing the Excel descriptions of each function to my descriptions and examples.</em></p>

<h2><strong>Date and Time Functions</strong></h2>

<p><strong>DAYS</strong> returns the number of days between two dates. For example, if you input that you received a payment on 1/01/2013 and another payment on 1/13/2013, the DAYS function tells you that the payments were spaced 12 days apart.</p>

<p><strong>ISOWEEKNUM</strong> returns the week number according to ISO standards. Followed by most European countries, the International Organization for Standardization (ISO 8601) states that all weeks begin on a Monday. Further, the first week of the year starts with the week that the first Thursday and January 4th fall within in. For example, 1/01/2012 is part of week 52 of 2011. Week 1 of 2012 begins on 1/02/2012 (Monday) and ends on 1/08/2012 (Sunday). Compare this function to the WEEKDAY function to gain a better understanding.</p>

<h2><strong>Engineering Functions</strong></h2>

<p><strong>BITAND</strong> runs the bitwise operation AND on two numbers. It converts them into binary code and returns 1 if and only if both numbers convert to 1 in binary; otherwise, it returns 0.</p>

<p><strong>BITOR</strong> runs the bitwise operation OR, which sets a bit to 1 if it finds any 1&#8217;s in the two bits and sets the bit to 0 if not. For example, BITOR will set the two bits 1 &amp; 0 to 1 and 0 &amp; 0 to 0.</p>

<p><strong>BITXOR</strong>, which is short for EXCLUSIVE OR, compares two bits and sets them to 1 if they are different and 0 if they are the same. For example, the bits 1 &amp; 0 become 1 while 1 &amp; 1 become 0.</p>

<p><strong>BITRSHIFT</strong> shifts bits to the right by a specified amount. For example, shifting by 1 moves all the bits in a sequence over to the right by 1, so that 000110 becomes 000011.</p>

<p><strong>BITLSHIFT</strong> shifts bits to the left by a specified amount. For example, shifting by 1 moves all the bits in a sequence over to the left by 1 so that 000110 becomes 001100.</p>

<p><strong>IMCOSH</strong> returns the hyperbolic cosine of a complex number. For example, if you want to get the hyperbolic cosine of 5 + 3i, running this function returns a result including both real and imaginary numbers. You must run this function in the format =IMCOSH(&#8220;5+3i&#8221;).</p>

<p><strong>IMCOT</strong> returns the hyperbolic cotangent of a complex number. You could change IMCOSH to IMCOT to calculate the hyperbolic cotangent of 5 + 3i.</p>

<p><strong>IMCSC</strong> provides the cosecant of a complex number. Note: this is not the hyperbolic cosecant; it is the trigonometric cosecant.</p>

<p><strong>IMCSCH</strong> provides the hyperbolic cosecant of a complex number. If you need this function, make sure you add the H on the end of the function so that you get the hyperbolic cosecant rather than the trigonometric cosecant.</p>

<p><strong>IMSEC</strong> provides the trigonometric secant of a complex number. As with cosecants, make sure you are using the correct function in order to get the type of secant you want.</p>

<p><strong>IMSECH</strong> provides the hyperbolic secant of a complex number. You can run this function by adding an H onto the end of the trigonometric function and rerunning. For example, if you had calculated the trigonometric secant of 5 + 3i by typing =IMSEC(&#8220;5+3i&#8221;) you could then run the hyperbolic secant by changing IMSEC to IMSECH.</p>

<p><strong>IMSINH</strong> calculates the hyperbolic sine of a complex number. As with all the other hyperbolic functions, simply place the expression in quotes that you want to run. For example, you could type =IMSINH(&#8220;5+3i&#8221;).</p>

<p><strong>IMTAN</strong> calculates the tangent of a complex number, such as the tangent of 5+3i.</p>

<h2><strong>Financial Functions</strong></h2>

<p><strong>PDURATION</strong> calculates how many periods are needed for an investment to reach a specific value. For example, if you want to know how long it&#8217;ll take for your investment (present value) to be worth $10,000 (future value), PDURATION can calculate how many periods you can expect to have to wait (depending on the interest rate).</p>

<p><strong>RRI</strong> is the complementary value to PDURATION. Instead of calculating how my periods are needed for the investment to reach a specific value, it calculates the interest rate on the investment if you know how long it will take to reach the value. For example, if PDURATION calculates that it will take 10 years for your investment to grow from $5,000 to $10,000, RRI can calculate an interest rate of 7.2 percent.</p>

<h2><strong>Information Functions</strong></h2>

<p><strong>ISFORMULA</strong>  checks whether a specific cell contains a formula. If yes, the result is &#8220;TRUE&#8221;; and if no, the result is &#8220;FALSE.&#8221;</p>

<p><strong>SHEET</strong> tells you which number sheet you are working with. For example, if you have 10 worksheets in a workbook and are working with the second worksheet created, SHEET will return a value of 2.</p>

<p><strong>SHEETS</strong> tells you how many sheets are in the workbook you are working with. For example, if there are 10 worksheets in the workbook, the SHEETS function will return a value of 10.</p>

<h2><strong>Logical Functions</strong></h2>

<p><strong>IFNA</strong> returns a specific value that you set if an expression resolves to N/A. Otherwise, it returns the expression&#8217;s value. For example, if you have a spreadsheet that has listings for different cities, you can use an IFNA function to return the expression, &#8220;Sorry, not found&#8221; if you search for a city that is not in the database using VLOOKUP.</p>

<p><strong>XOR</strong> tests whether any of the parameters you set are true. If any parameter is true, it returns a value of &#8220;true.&#8221; Otherwise it returns a value of &#8220;false.&#8221; For example, if you use XOR to test whether your sales are greater than $500, your profit is more than 20 percent of your sales and you have at least 20 new customers this month, you will get a response of &#8220;true&#8221; if any of those criteria are met.</p>

<h2><strong>Lookup and Reference Functions</strong></h2>

<p><strong>FORMULATEXT</strong> shows you the formula that is listed in a particular cell so that you can see it and check for any errors. For example, if you run =FORMULATEXT(R1) in cell R4, it puts the formula found at R1 into R4.</p>

<h2><strong>Math and Trigonometry Functions</strong></h2>

<p><strong>ACOT</strong> calculates the arccotangent of a particular number. You need to use real numbers to use this function. For example, if the cotangent is 2, you can run ACOT(2) to find out the arccotangent. ACOT calculates arccotangents in radians.</p>

<p><strong>ACOTH</strong> calculates the hyperbolic arccotangent rather than the standard arccotangent. For example, you can use ACOTH(2) to find the hyperbolic arccotangent of 2.</p>

<p><strong>ARABIC</strong> converts numerals from Roman to Arabic. For example, you can run ARABIC(XIII) to get the result of &#8220;13.&#8221; You can also tell ARABIC to convert the contents of a cell into Arabic numerals For example, if cell A2 contains the number CXLIII, you can run ARABIC(A2) to get the result &#8220;143.&#8221;</p>

<p><strong>BASE</strong> converts hexadecimal numbers into numbers of whatever base you want with a specified minimum length. For example, you can convert hexidecimal numbers into base 2 with a minimum length of 10 using this function.</p>

<p><strong>CEILING.MATH</strong> rounds numbers up according you your specifications. You can either round numbers up to the nearest integer or the nearest multiple. For example, you can round 8.76 up to 9 (the nearest integer) or up to the nearest multiple of 5, which would be 10. You can also specify whether you want to round negative numbers towards zero or away from zero.</p>

<p><strong>COMBINA</strong> returns the number of combinations for a given number, including repetitions. For example, if you want to know how many three-letter combinations of a five-letter set are possible, you would run COMBINA (5,3) to get an answer of 35.</p>

<p><strong>COT</strong> gives you the cotangent of an angle in radians. You need to know the measurement of the angle in radians to run this function. For example, you can run COT(5) to find out the cotangent in radians of a 5-radian angle.</p>

<p><strong>COTH</strong> gives you the hyperbolic cotangent of a hyperbolic angle. For example, if your hyperbolic angle is 5, run COTH(5). Be careful not to mix COTH and COT up as they are different types of cotangents.</p>

<p><strong>CSC</strong> calculates the cosecant in radians of an angle. Make sure that you convert the angle to radians if you measure it in degrees. For example, if you have a 142 degree angle, convert it to 2.478 radians before running CSC(2.478) to find the cosecant.</p>

<p><strong>CSCH</strong> calculates the hyperbolic cosecant of an angle in radians. Run CSCH(angle) to get this result; make sure you only run CSCH if you want the hyperbolic cosecant, not the standard cosecant.</p>

<p><strong>DECIMAL</strong> converts a number into hexadecimal format. You need to know the base the number is written in so that you can convert it appropriately. For example, you can convert FF from base 16 to the hexadecimal equivalent, which is 255, using this function.</p>

<p><strong>FLOOR.MATH</strong> is the opposite of CEILING.MATH; it rounds numbers <em>down</em> to the nearest integer or multiple. For example, you could round 8.142 down to 8 or down to 6 (the nearest multiple of 3) using FLOOR.MATH.</p>

<p><strong>ISO.CEILING</strong> is similar to CEILING.MATH but does not take sign into account. For example, with CEILING.MATH you can ask it to round -3.41  further away from zero (-4) because of the sign. ISO.CEILING will round this number to -3 unless you specify a multiple such as nearest multiple of 2, in which case it will round up to -2.</p>

<p><strong>MUNIT</strong> displays a matrix of a dimension you specify, which needs to be entered as an array. For example, MUNIT(3) returns a 3x3 matrix.</p>

<p><strong>SEC</strong> calculates the secant of an angle in radians. For example, you can run SEC(2.478) to find the secant of an angle that measures 2.478 radians.</p>

<p><strong>SECH</strong> calculates the hyperbolic secant of an angle in radians. Use this function only for hyperbolic, not standard, secants of angles.</p>

<h2><strong>Statistical Functions</strong></h2>

<p><strong>BINOM.DIST.RANGE</strong> calculates the statistical probability of an outcome based on the results of a trial, using a binomial distribution curve. To perform this calculation, you need to know how many trials were performed and how many were successful. You also need to know the probability of success. For example, if your trial was flipping a coin 50 times to try to get heads and you got 10 heads, you would run BINOM.DIST.RANGE(50,.5,10).</p>

<p><strong>GAMMA</strong> returns the gamma value of a number. For example, GAMMA(132) calculates the gamma function of 132.</p>

<p><strong>GAUSS</strong> calculates the probability that a member of a standard normal population will fall somewhere between the mean and a specific number of standard deviations from the mean. For example, if you want to calculate the probability that somebody&#8217;s test results will be less than three standard deviations from the mean, you would run GAUSS(3).</p>

<p><strong>PERMUTATIONA</strong> calculates the number of permutations including repetitions that are possible for a particular set. To use this function, you need to know the number of objects in the set and the number that will be chosen.</p>

<p><strong>PHI</strong> determines the phi value, or the value of the density function for a standard normal distribution. For example, PHI (1.43) calculates the density function for a standard normal distribution with a value of 1.43.</p>

<p><strong>SKEW.P</strong> tells you how much a distribution is skewed based on its population. Usually, you input the data from the population then run SKEW.P on the entire data set.</p>

<h2><strong>Text Functions</strong></h2>

<p><strong>NUMBERVALUE</strong> changes text to numbers based on locale-independent method. For example, 3.5% will be converted into .035.</p>

<p><strong>UNICHAR</strong> converts a number into the unicode character associated with that number. For example, UNICHAR(66) returns a value of B.</p>

<p><strong>UNICODE</strong> is the complement of UNICHAR; it returns the number associated with a particular character. For example, UNICODE(B) returns a value of 66.</p>

<h2><strong>Web Functions</strong></h2>

<p><strong>ENCODEURL</strong> converts a string of text into URL code so that you can filter results of a database. For example, ENCODEURL(&#8220;michael herman&#8221;) returns michael%20herman.</p>

<p><strong>FILTERXML</strong> returns XML data from a specified XML path. You must provide the XML.</p>

<p><strong>WEBSERVICE</strong> returns data from an online service. You must provide the URL for WEBSERVICE to draw from.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/11/08/recursively-scraping-web-pages-with-scrapy/">Recursively Scraping Web Pages With Scrapy</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-11-08T15:39:00-08:00" pubdate data-updated="true">Nov 8<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>In the first <a href="http://mherman.org/blog/2012/11/05/scraping-web-pages-with-scrapy/">tutorial</a>, I showed you how to write a crawler with Scrapy to scrape Craiglist Nonprofit jobs in San Francisco and store the data to a CSV file. This tutorial continues from where we left off, adding to the existing code, in order to build a recursive crawler to scrape multiple pages. Make sure you read the first tutorial first.</em></p>

<p><strong>CrawlSpider:</strong> Last time, we created a new Scrapy project, updated the Item Class, and then wrote the spider to pull jobs from a single page. This time, we just need to do some basic changes to add the ability to follow links and scrape more than one page. The first change is that this spider will inherit CrawlSpider and not BaseSpider.</p>

<p><strong>Rules: </strong>We need to add in some Rules objects to define how the crawler follows the links. We will be using the following <a href="https://scrapy.readthedocs.org/en/latest/topics/spiders.html?highlight=crawlspider#crawling-rules">rules</a>:</p>

<ul>
<li><em>SgmlLinkExtractor: </em>defines how you want the spider to follow the links

<ul>
<li><em>allow:</em> defines the link href</li>
<li><em>restrict_xpaths: </em>restricts the link to a certain Xpath</li>
</ul>
</li>
<li><em>callback: </em>calls the parsing function after each page is scraped*</li>
<li><em>follow: </em>instructs whether to continue following the links as long as they exist</li>
</ul>


<p>*Please Note: Make sure you rename the parsing function to something besides &#8220;parse&#8221; as the CrawlSpider uses the parse method to implement its logic.</p>

<p><em><em>Release:</em> </em>Once updated, the final code looks like this:</p>

<pre><code>from scrapy.contrib.spiders import CrawlSpider, Rule
from scrapy.contrib.linkextractors.sgml import SgmlLinkExtractor
from scrapy.selector import HtmlXPathSelector
from craigslist_sample.items import CraigslistSampleItem

class MySpider(CrawlSpider):
    name = "craigs"
    allowed_domains = ["sfbay.craigslist.org"]
    start_urls = ["http://sfbay.craigslist.org/npo/"]   

    rules = (Rule (SgmlLinkExtractor(allow=("index\d00\.html", ),restrict_xpaths=('//p[@id="nextpage"]',))
    , callback="parse_items", follow= True),
    )

    def parse_items(self, response):
        hxs = HtmlXPathSelector(response)
        titles = hxs.select("//p")
        items = []
        for titles in titles:
            item = CraigslistSampleItem()
            item ["title"] = titles.select("a/text()").extract()
            item ["link"] = titles.select("a/@href").extract()
            items.append(item)
        return(items)
</code></pre>

<p>Now run the following command to release the spider and save the scraped data to a CSV file:</p>

<pre><code>scrapy crawl craigs -o items.csv -t csv
</code></pre>

<p><em>In essence, this spider started crawling at http://sfbay.craigslist.org/npo/ and then followed the &#8220;next 100 postings&#8221; link at the bottom, scraping the next page, until there where no more links to crawl. Again, this can be used to create some powerful crawlers, so use with caution and set delays to throttle the crawling speed if necessary.</em></p>

<p>You can find the source code on <a href="https://github.com/mjhea0/Scrapy-Samples">Github</a>.</p>

<hr />

<div class="embed-video-container"><iframe src="http://www.youtube.com/embed/P-_TpZ54Vcw "></iframe></div>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/11/05/scraping-web-pages-with-scrapy/">Scraping Web Pages With Scrapy</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-11-05T14:59:00-08:00" pubdate data-updated="true">Nov 5<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>This is a simple tutorial on how to write a crawler using Scrapy (BaseSpider) to scrape and parse Craigslist Nonprofit jobs in San Francisco and store the data to a CSV file. If you don&#8217;t have any experience with Scrapy, start by reading this <a href="http://doc.scrapy.org/en/latest/intro/tutorial.html">tutorial</a>. Also, I assume that you are familiar with Xpath; if not, please read the Xpath basic <a href="http://w3schools.com/xpath/">tutorial</a> on w3schools. Enjoy!</em></p>

<p><strong>Installation:</strong> Start by <a href="http://scrapy.org/">downloading</a> and installing Scrapy and all its dependencies. Refer to this <a href="http://www.youtube.com/watch?v=eEK2kmmvIdw">video</a>, if you need help.</p>

<p><strong>Create Project:</strong> Once installed, open your terminal and create a Scrapy project by navigating to the directory you&#8217;d like to store your project in and then running the following command:</p>

<pre><code>scrapy startproject craigslist_sample
</code></pre>

<p><strong>Item Class:</strong> Open the items.py within the ~craigslist_sample\craigslist_sample directory. Edit the items.py file to define the fields that you want contained with the Item. Since we want the post title and subsequent URL, the Item class looks like this:</p>

<pre><code># Define here the models for your scraped items

from scrapy.item import Item, Field

class CraigslistSampleItem(Item):
    title = Field()
    link = Field()
</code></pre>

<p><strong>The Spider:</strong> The spider defines the initial URL (http://sfbay.craigslist.org/npo/), how to follow links/pagination (if necessary), and how to extract and parse the fields defined above. The spider must define these attributes:</p>

<ul>
<li><em>name</em>: the spider&#8217;s unique identifier</li>
<li><em>start_urls</em>: URLs the spider begins crawling at</li>
<li><em>parse</em>: method that parses and extracts the scraped data, which will be called with the downloaded Response object of each start URL</li>
</ul>


<p>You also need to use the HtmlXpathSelector for working with Xpaths. Visit the Scrapy <a href="http://doc.scrapy.org/en/0.16/">tutorial</a> for more information. The following is the code for the basic spider:</p>

<pre><code>from scrapy.spider import BaseSpider
from scrapy.selector import HtmlXPathSelector
from craigslist_sample.items import CraigslistSampleItem

class MySpider(BaseSpider):
    name = "craig"
    allowed_domains = ["craigslist.org"]
    start_urls = ["http://sfbay.craigslist.org/npo/"]

    def parse(self, response):
        hxs = HtmlXPathSelector(response)
        titles = hxs.select("//p")
        for titles in titles:
            title = titles.select("a/text()").extract()
            link = titles.select("a/@href").extract()
            print title, link
</code></pre>

<p>Save this in the ~\craigslist_sample\craigslist_sample\spiders directory as test.py.</p>

<p><strong>Trial:</strong> Now you are ready for a trial run of the scraper. So, while in the root directory of your Scrapy project, run the following command to output the scraped data to the screen:</p>

<pre><code>scrapy crawl craig
</code></pre>

<p><strong>Dicts:</strong> The Item objects defined above are simply custom dicts. Use the standard dict syntax to return the extracted data inside the Item objects:</p>

<pre><code>item = CraigslistSampleItem()
item ["title"] = titles.select("a/text()").extract()
item ["link"] = titles.select("a/@href").extract()
</code></pre>

<p><strong>Release:</strong> Once complete, the final code looks like this:</p>

<pre><code>from scrapy.spider import BaseSpider
from scrapy.selector import HtmlXPathSelector
from craigslist_sample.items import CraigslistSampleItem

class MySpider(BaseSpider):
    name = "craig"
    allowed_domains = ["craigslist.org"]
    start_urls = ["http://sfbay.craigslist.org/npo/"]

    def parse(self, response):
        hxs = HtmlXPathSelector(response)
        titles = hxs.select("//p")
        items = []
        for titles in titles:
            item = CraigslistSampleItem()
            item ["title"] = titles.select("a/text()").extract()
            item ["link"] = titles.select("a/@href").extract()
            items.append(item)
        return items
</code></pre>

<p><strong>Store the data: </strong>The scraped data can now be <a href="http://doc.scrapy.org/en/0.16/topics/feed-exports.html#topics-feed-exports">stored</a> in these formats- JSON, CSV, and XML (among others). Run the following command to save the data in CSV:</p>

<pre><code>scrapy crawl craig -o items.csv -t csv
</code></pre>

<p>You should now have a CSV file in your directory called items.csv full of data:</p>

<p><img src="http://www.backwardsteps.com/uploads/2012-11-05_1411.png" alt="" /></p>

<p><em>Although this is relatively simple tutorial, there are still powerful things you can do by just customizing this basic script. Just remember to not overload the server on the website you are crawling. Scrapy allows you to set <a href="https://scrapy.readthedocs.org/en/latest/topics/settings.html?highlight=delay#download-delay">delays</a> to throttle the crawling speed.</em></p>

<hr />

<div class="embed-video-container"><iframe src="http://www.youtube.com/embed/1EFnX1UkXVU "></iframe></div>


<hr />

<p><em>In my next post I&#8217;ll show how to use Scrapy to  recursively crawl a site by following links. Until then, you can find the code for this project on <a href="https://github.com/mjhea0/Scrapy-Samples">Github</a>.</em></p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/5/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/3/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
	<br />
	<a class="sitelink" href="https://twitter.com/mikeherman" target="_blank"><img class="icon" src="https://raw.github.com/mjhea0/mjhea0.github.com/master/images/social/24px/twitter.png"/></a>
	<a href="http://www.linkedin.com/pub/michael-herman/3b/a94/4" target="_blank"><img alt="" src="https://raw.github.com/mjhea0/mjhea0.github.com/master/images/social/24px/linkedin.png"/></a>
	<a href="http://bit.ly/TzGt2K" target="_blank"><img alt="" src="https://raw.github.com/mjhea0/mjhea0.github.com/master/images/social/24px/youtube.png"/></a>
	<a href="https://github.com/mjhea0" target="_blank"><img alt="" src="https://raw.github.com/mjhea0/mjhea0.github.com/master/images/social/24px/github.png"/></a>
	
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/12/30/django-basics/">Django Basics - Installing Django and Setting up a Project and App</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/12/excel-tips-how-to-cut-down-on-calculations-using-sumif-and-sumifs/">Excel Tips: How to Cut Down on Calculations Using SUMIF and SUMIFS</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/10/crash-course-in-web2py-part-5-modifying-the-appearance-and-deploying-the-web-form/">Crash Course in web2py (part 5 - modifying the appearance and deploying the web form)</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/09/crash-course-in-web2py-part-4-managing-form-records/">Crash Course in web2py (part 4 - managing form records)</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/12/06/crash-course-in-web2py-part-3-form-validation/">Crash Course in web2py (part 3 - form validation)</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>
  <ul id="categories">
    <li class='category'><a href='/blog/categories/analytics/'>analytics (5)</a></li>
<li class='category'><a href='/blog/categories/excel/'>excel (3)</a></li>
<li class='category'><a href='/blog/categories/python/'>python (9)</a></li>

  </ul>
</section><section>

</section>







  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Michael Herman &copy; 2012 -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span> -
  <a href="https://github.com/mjhea0/mjhea0.github.com">Fork me on Github</a>

</p>

</footer>
  



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
