<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Node | Michael Herman]]></title>
  <link href="http://mherman.org/blog/categories/node/atom.xml" rel="self"/>
  <link href="http://mherman.org/"/>
  <updated>2017-06-01T09:42:57-06:00</updated>
  <id>http://mherman.org/</id>
  <author>
    <name><![CDATA[Michael Herman]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Developing Microservices - Node, React, and Docker]]></title>
    <link href="http://mherman.org/blog/2017/05/11/developing-microservices-node-react-docker/"/>
    <updated>2017-05-11T08:16:46-06:00</updated>
    <id>http://mherman.org/blog/2017/05/11/developing-microservices-node-react-docker</id>
    <content type="html"><![CDATA[<p>In this post you will learn how to quickly spin up a reproducible development environment with Docker to manage a number of Node.js microservices.</p>

<div style="text-align:center;">
  <img src="http://mherman.org/images/blog/docker-microservices.png" style="max-width: 100%; border:0; box-shadow: none;" alt="microservice architecture">
</div>


<p><br></p>

<p>This post assumes prior knowledge of the following topics. Refer to the resources for more info:</p>

<table>
<thead>
<tr>
<th> Topic            </th>
<th> Resource </th>
</tr>
</thead>
<tbody>
<tr>
<td> Docker           </td>
<td> <a href="https://docs.docker.com/engine/getstarted/">Get started with Docker</a> </td>
</tr>
<tr>
<td> Docker Compose   </td>
<td> <a href="https://docs.docker.com/compose/gettingstarted/">Get started with Docker Compose</a> </td>
</tr>
<tr>
<td> Node/Express API </td>
<td> <a href="http://mherman.org/blog/2016/09/12/testing-node-and-express">Testing Node and Express</a> </td>
</tr>
<tr>
<td> React </td>
<td> <a href="https://github.com/mjhea0/node-workshop/blob/master/w2/lessons/03-react.md">React Intro</a></td>
</tr>
<tr>
<td> TestCafe </td>
<td> <a href="http://mherman.org/blog/2017/03/19/functional-testing-with-testcafe">Functional Testing With TestCafe</a></td>
</tr>
<tr>
<td> Swagger </td>
<td> <a href="http://mherman.org/blog/2016/05/26/swagger-and-nodejs/">Swagger and NodeJS</a></td>
</tr>
</tbody>
</table>


<blockquote><p><strong>NOTE</strong>: Looking for a slightly easier implementation? Check out my previous post - <a href="http://mherman.org/blog/2017/04/18/developing-and-testing-microservices-with-docker">Developing and Testing Microservices With Docker</a>.</p></blockquote>

<h2>Contents</h2>

<ol>
<li>Objectives</li>
<li>Architecture</li>
<li>Project Setup</li>
<li>Users Service</li>
<li>Web Service - part 1</li>
<li>Movies Service</li>
<li>Web Service - part 2</li>
<li>Workflow</li>
<li>Test Setup</li>
<li>Swagger Setup</li>
<li>Next Steps</li>
</ol>


<h2>Objectives</h2>

<p>By the end of this tutorial, you should be able to&hellip;</p>

<ol>
<li>Configure and run microservices locally with Docker and Docker Compose</li>
<li>Utilize <a href="https://docs.docker.com/engine/tutorials/dockervolumes/">volumes</a> to mount your code into a container</li>
<li>Run unit and integration tests inside a Docker container</li>
<li>Test the entire set of services with functional, end-to-end tests</li>
<li>Debug a running Docker container</li>
<li>Enable services running in different containers to talk to one other</li>
<li>Secure your services via JWT-based authentication</li>
<li>Work with React running inside a Docker Container</li>
<li>Configure Swagger to interact with a service</li>
</ol>


<h2>Architecture</h2>

<p>The end goal of this post is to organize the technologies from the above image into the following containers and services:</p>

<table>
<thead>
<tr>
<th> Name             </th>
<th> Service </th>
<th> Container </th>
<th> Tech                 </th>
</tr>
</thead>
<tbody>
<tr>
<td> Web              </td>
<td> Web     </td>
<td> web       </td>
<td> React, React-Router  </td>
</tr>
<tr>
<td> Movies API       </td>
<td> Movies  </td>
<td> movies    </td>
<td> Node, Express        </td>
</tr>
<tr>
<td> Movies DB        </td>
<td> Movies  </td>
<td> movies-db </td>
<td> Postgres             </td>
</tr>
<tr>
<td> Swagger          </td>
<td> Movies  </td>
<td> swagger   </td>
<td> Swagger UI           </td>
</tr>
<tr>
<td> Users API        </td>
<td> Users   </td>
<td> users     </td>
<td> Node, Express        </td>
</tr>
<tr>
<td> Users DB         </td>
<td> Users   </td>
<td> users-db  </td>
<td> Postgres             </td>
</tr>
<tr>
<td> Functional Tests </td>
<td> Test    </td>
<td> n/a       </td>
<td> TestCafe             </td>
</tr>
</tbody>
</table>


<p>Let&rsquo;s get started!</p>

<h2>Project Setup</h2>

<p>Start by cloning the base project and then checking out the first tag:</p>

<pre><code class="sh">$ git clone https://github.com/mjhea0/microservice-movies
$ cd microservice-movies
$ git checkout tags/v1
</code></pre>

<p>Overall project structure:</p>

<pre><code class="sh">.
├── services
│   ├── movies
│   │   ├── src
│   │   │   └── db
│   │   └── swagger
│   ├── users
│   │   └── src
│   │       └── db
│   └── web
└── tests
</code></pre>

<p>Before we add Docker, be sure to review the code so that you have a basic understanding of how everything works. Feel free to test these services as well&hellip;</p>

<p><em>Users:</em></p>

<ul>
<li>Navigate to &ldquo;services/users&rdquo;</li>
<li><code>npm install</code></li>
<li>update the <code>start</code> script within <em>package.json</em> to <code>"gulp --gulpfile gulpfile.js"</code></li>
<li><code>npm start</code></li>
<li>Open <a href="http://localhost:3000/users/ping">http://localhost:3000/users/ping</a> in your browser</li>
</ul>


<p><em>Movies:</em></p>

<ul>
<li>Navigate to &ldquo;services/movies&rdquo;</li>
<li><code>npm install</code></li>
<li>update the <code>start</code> script within <em>package.json</em> to <code>"gulp --gulpfile gulpfile.js"</code></li>
<li><code>npm start</code></li>
<li>Open <a href="http://localhost:3000/movies/ping">http://localhost:3000/movies/ping</a> in your browser</li>
</ul>


<p><em>Web:</em></p>

<ul>
<li>Navigate to &ldquo;services/web&rdquo;</li>
<li><code>npm install</code></li>
<li><code>npm start</code></li>
<li>Open <a href="http://localhost:3006">http://localhost:3006</a> in your browser. You should see the log in page.</li>
</ul>


<p>Next, add a <em>docker-compose.yml</em> file to the project root. This file is used by Docker Compose to link multiple services together. With one command it will spin up all the containers we need and enable them to communicate with one another (as needed).</p>

<p>With that, let&rsquo;s get each service going, making sure to test as we go&hellip;</p>

<h2>Users Service</h2>

<p>We&rsquo;ll start with the database since the API is dependent on it being up&hellip;</p>

<h3>Database</h3>

<p>First, add a <em>Dockerfile</em> to &ldquo;services/users/src/db&rdquo;:</p>

<pre><code>FROM postgres

# run create.sql on init
ADD create.sql /docker-entrypoint-initdb.d
</code></pre>

<p>Here, we extend the official Postgres image by adding a SQL file to the &ldquo;docker-entrypoint-initdb.d&rdquo; directory in the container, which will execute on init.</p>

<p>Then update the <em>docker-compose.yml</em> file:</p>

<pre><code>version: '2.1'

services:

  users-db:
    container_name: users-db
    build: ./services/users/src/db
    ports:
      - '5433:5432' # expose ports - HOST:CONTAINER
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    healthcheck:
      test: exit 0
</code></pre>

<p>This config will create a container called <code>users-db</code>, from the <em>Dockerfile</em> found in &ldquo;services/users/src/db&rdquo;. (Directories are relative to the <em>docker-compose.yml</em> file.)</p>

<p>Once spun up, environment variables will be added and an exit code of <code>0</code> will be sent after it&rsquo;s successfully up and running. Postgres will be available on port <code>5433</code> on the host machine and on port <code>5432</code> for other services.</p>

<blockquote><p><strong>NOTE:</strong> Use <code>expose</code>, rather than <code>ports</code>, if you just want Postgres available to other services but not the host machine:</p>

<pre><code>expose:
  - "5432"
</code></pre></blockquote>

<p>Take note of the version used - <code>2.1</code>. This does not relate directly to the version of Docker Compose installed; instead, it specifies the file format that you want to use.</p>

<p>Fire up the container:</p>

<pre><code class="sh">$ docker-compose up --build -d users-db
</code></pre>

<p>Once up, let&rsquo;s run a quick sanity check. Enter the shell:</p>

<pre><code class="sh">$ docker-compose run users-db bash
</code></pre>

<p>Then run <code>env</code> to ensure that the proper environment variables are set. You can also check out the &ldquo;docker-entrypoint-initdb.d&rdquo; directory:</p>

<pre><code class="sh"># cd docker-entrypoint-initdb.d/
# ls
create.sql
</code></pre>

<p><code>exit</code> when done.</p>

<h3>API</h3>

<p>Turning to the API, add a <em>Dockerfile</em> to &ldquo;services/users&rdquo;, making sure to review the comments:</p>

<pre><code>FROM node:latest

# set working directory
RUN mkdir /usr/src/app
WORKDIR /usr/src

# add `/usr/src/node_modules/.bin` to $PATH
ENV PATH /usr/src/node_modules/.bin:$PATH

# install and cache app dependencies
ADD package.json /usr/src/package.json
RUN npm install

# start app
CMD ["npm", "start"]
</code></pre>

<blockquote><p><strong>NOTE</strong>: Be sure to take advantage of Docker&rsquo;s layered <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#build-cache">cache</a> system, to speed up build times, by adding the <em>package.json</em> and installing the dependencies <strong>before</strong> adding the app&rsquo;s source files. For more on this, check out <a href="http://bitjudo.com/blog/2014/03/13/building-efficient-dockerfiles-node-dot-js/">Building Efficient Dockerfiles - Node.js</a>.</p></blockquote>

<p>Then add the <code>users-service</code> to the <em>docker-compose.yml</em> file:</p>

<pre><code>users-service:
  container_name: users-service
  build: ./services/users/
  volumes:
    - './services/users:/usr/src/app'
    - './services/users/package.json:/usr/src/package.json'
  ports:
    - '3000:3000' # expose ports - HOST:CONTAINER
  environment:
    - DATABASE_URL=postgres://postgres:postgres@users-db:5432/users_dev
    - DATABASE_TEST_URL=postgres://postgres:postgres@users-db:5432/users_test
    - NODE_ENV=${NODE_ENV}
    - TOKEN_SECRET=changeme
  depends_on:
    users-db:
      condition: service_healthy
  links:
    - users-db
</code></pre>

<p>What&rsquo;s happening here?</p>

<ul>
<li><code>volumes</code>: <a href="https://docs.docker.com/engine/tutorials/dockervolumes/">volumes</a> are used to mount a directory inside a container so that you can make modifications to the code without having to rebuild the image. This should be a default in your local development environment so you quickly get feedback on code changes.</li>
<li><code>depends_on</code>: <a href="https://docs.docker.com/compose/compose-file/#dependson">depends_on</a> specifies the order in which to start services. In this case, the <code>users-service</code> will wait for the <code>users-db</code> to fire up successfully (with an exit code of <code>0</code>) before it starts.</li>
<li><code>links</code>: With <a href="https://docs.docker.com/compose/compose-file/#links">links</a> you can link to services running in other containers. So, with this config, code inside the <code>users-service</code> will be able to access the database via <code>users-db:5432</code>.</li>
</ul>


<blockquote><p><strong>NOTE:</strong> Curious about the difference between <code>depends_on</code> and <code>links</code>? Check out the following <a href="http://stackoverflow.com/a/39658359/1799408">Stack Overflow discussion</a> for more info.</p></blockquote>

<p>Set the <code>NODE_ENV</code> environment variable:</p>

<pre><code class="sh">$ export NODE_ENV=development
</code></pre>

<p>Build the image and spin up the container:</p>

<pre><code class="sh">$ docker-compose up --build -d users-service
</code></pre>

<blockquote><p><strong>NOTE:</strong> Keep in mind that Docker Compose handles both the build and run times. This can be confusing. For example, take a look at the current docker-compose.yml file - What is happening at the build time? How about the run time? How do you know?</p></blockquote>

<p>Once up, create a new file in the project root called <em>init_db.sh</em> and add the Knex migrate and seed commands:</p>

<pre><code class="sh">#!/bin/sh

docker-compose run users-service knex migrate:latest --env development --knexfile app/knexfile.js
docker-compose run users-service knex seed:run --env development --knexfile app/knexfile.js
</code></pre>

<p>Then apply the migrations and add the seed:</p>

<pre><code class="sh">$ sh init_db.sh
Using environment: development
Batch 1 run: 1 migrations
/src/src/db/migrations/20170504191016_users.js
Using environment: development
Ran 1 seed files
/src/src/db/seeds/users.js
</code></pre>

<p>Test:</p>

<table>
<thead>
<tr>
<th> Endpoint        </th>
<th> HTTP Method </th>
<th> CRUD Method </th>
<th> Result        </th>
</tr>
</thead>
<tbody>
<tr>
<td> /users/ping     </td>
<td> GET         </td>
<td> READ        </td>
<td> <code>pong</code>        </td>
</tr>
<tr>
<td> /users/register </td>
<td> POST        </td>
<td> CREATE      </td>
<td> add a user    </td>
</tr>
<tr>
<td> /users/login    </td>
<td> POST        </td>
<td> CREATE      </td>
<td> log in a user </td>
</tr>
<tr>
<td> /users/user     </td>
<td> GET         </td>
<td> READ        </td>
<td> get user info </td>
</tr>
</tbody>
</table>


<pre><code class="sh">$ http POST http://localhost:3000/users/register username=foo password=bar
$ http POST http://localhost:3000/users/login username=foo password=bar
</code></pre>

<blockquote><p><strong>NOTE:</strong> <code>http</code> in the above commands is part of the <a href="https://httpie.org/">HTTPie</a> library, which is a wrapper on top of cURL.</p></blockquote>

<p>In both cases you should see a <code>status</code> of <code>success</code> along with a <code>token</code>, i.e. -</p>

<pre><code class="sh">{
    "status": "success",
    "token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9"
}
</code></pre>

<p>Finally, run the unit and integration tests:</p>

<pre><code class="sh">$ docker-compose run users-service npm test
</code></pre>

<p>You should see:</p>

<pre><code>routes : index
  GET /does/not/exist
    ✓ should throw an error

routes : users
  POST /users/register
    ✓ should register a new user (178ms)
  POST /users/login
    ✓ should login a user (116ms)
    ✓ should not login an unregistered user
    ✓ should not login a valid user with incorrect password (125ms)
  GET /users/user
    ✓ should return a success (114ms)
    ✓ should throw an error if a user is not logged in

auth : helpers
  comparePass()
    ✓ should return true if the password is correct (354ms)
    ✓ should return false if the password is correct (315ms)
    ✓ should return false if the password empty (305ms)

auth : local
  encodeToken()
    ✓ should return a token
  decodeToken()
    ✓ should return a payload


12 passing (4s)
</code></pre>

<p>Check the test specs for more info. That&rsquo;s it! Let&rsquo;s move on to the web service&hellip;</p>

<h2>Web Service - part 1</h2>

<p>With our users service up and running, we can turn our attention to the client-side and spin up the React app inside a container to test authentication.</p>

<blockquote><p><strong>NOTE:</strong> The React code is ported from <a href="https://github.com/blackstc/intro-react-redux-omdb">intro-react-redux-omdb</a> and <a href="https://github.com/etmoore/communikey">communikey</a> written by <a href="https://www.linkedin.com/in/charlieblackstock/">Charlie Blackstock</a> and <a href="https://www.linkedin.com/in/etmoore1/">Evan Moore</a>, respectively - two of my former students.</p></blockquote>

<p>Add a <em>Dockerfile</em> to &ldquo;services/web&rdquo;:</p>

<pre><code>FROM node:latest

# set working directory
RUN mkdir /usr/src/app
WORKDIR /usr/src/app

# add `/usr/src/app/node_modules/.bin` to $PATH
ENV PATH /usr/src/app/node_modules/.bin:$PATH

# install and cache app dependencies
ADD package.json /usr/src/app/package.json
RUN npm install
RUN npm install react-scripts@0.9.5 -g

# start app
CMD ["npm", "start"]
</code></pre>

<p>As of 05/10/2017 the <a href="http://www.omdbapi.com/">OMDb API</a> is private, so you have to donate at least $1 to gain access. Once you have an API Key, update the <code>API_URL</code> in <em>services/web/src/App.jsx</em>:</p>

<pre><code class="javascript">const API_URL = 'http://www.omdbapi.com/?apikey=addyourkey&amp;s='
</code></pre>

<p>Then update the <em>docker-compose.yml</em> file like so:</p>

<pre><code>web-service:
  container_name: web-service
  build: ./services/web/
  volumes:
    - './services/web:/usr/src/app'
    - '/usr/src/app/node_modules'
  ports:
    - '3007:3006' # expose ports - HOST:CONTAINER
  environment:
    - NODE_ENV=${NODE_ENV}
  depends_on:
    users-service:
      condition: service_started
  links:
    - users-service
</code></pre>

<blockquote><p><strong>NOTE:</strong> To prevent the volume - <code>/usr/src/app</code> - from overriding the <em>package.json</em>, we used a data volume - <code>/usr/src/app/node_modules</code>. This may or may not be necessary, depending on the order in which you set up your image and containers. Check out <a href="http://dchua.com/2016/02/07/getting-npm-packages-to-be-installed-with-docker-compose/">Getting npm packages to be installed with docker-compose</a> for more.</p></blockquote>

<p>Build the image and fire up the container:</p>

<pre><code class="sh">$ docker-compose up --build -d web-service
</code></pre>

<blockquote><p><strong>NOTE:</strong> To avoid dealing with too much configuration (babel and webpack), the React app uses <a href="https://github.com/facebookincubator/create-react-app">Create React App</a>.</p></blockquote>

<p>Open your browser and navigate to <a href="http://localhost:3007">http://localhost:3007</a>. You should see the login page:</p>

<div style="text-align:center;">
  <img src="http://mherman.org/images/blog/microservice-movies-login.png" style="max-width: 100%; border:0; box-shadow: none;" alt="login page">
</div>


<p>Log in with -</p>

<ul>
<li>username: <code>foo</code></li>
<li>password: <code>bar</code></li>
</ul>


<p>Once logged in you should see:</p>

<div style="text-align:center;">
  <img src="http://mherman.org/images/blog/microservice-movies-search.png" style="max-width: 100%; border:0; box-shadow: none;" alt="search page">
</div>


<p>Within <em>services/web/src/App.jsx</em>, let&rsquo;s take a quick look at the AJAX request in the <code>loginUser()</code> method:</p>

<pre><code class="javascript">loginUser (userData, callback) {
  /*
    why? http://localhost:3000/users/login
    why not? http://users-service:3000/users/login
   */
  return axios.post('http://localhost:3000/users/login', userData)
  .then((res) =&gt; {
    window.localStorage.setItem('authToken', res.data.token)
    window.localStorage.setItem('user', res.data.user)
    this.setState({ isAuthenticated: true })
    this.createFlashMessage('You successfully logged in! Welcome!')
    this.props.history.push('/')
    this.getMovies()
  })
  .catch((error) =&gt; {
    callback('Something went wrong')
  })
}
</code></pre>

<p>Why do we use <code>localhost</code> rather than the name of the container, <code>users-service</code>? This request is originating outside the container, on the host. Keep in mind, that if, this request was originating inside the container, we would need to use the container name rather than <code>localhost</code>, since <code>localhost</code> would refer back to the container itself in that situation.</p>

<p>Make sure you can log out and register as well.</p>

<p>Next, let&rsquo;s spin up the movies service so that end users can save movies to a collection&hellip;</p>

<h2>Movies Service</h2>

<p>Set up for the movies service is nearly the same as the users service. Try this on your own to check your understanding:</p>

<ol>
<li>Database

<ul>
<li>add a <em>Dockerfile</em></li>
<li>update the <em>docker-compose.yml</em></li>
<li>spin up the container</li>
<li>test</li>
</ul>
</li>
<li>API

<ul>
<li>add a <em>Dockerfile</em></li>
<li>update the <em>docker-compose.yml</em> (make sure to link the service with the database and the users service and update the exposed ports - <code>3001</code> for the api, <code>5434</code> for the db)</li>
<li>spin up the container</li>
<li>apply migrations and seeds</li>
<li>test</li>
</ul>
</li>
</ol>


<blockquote><p><strong>NOTE:</strong> Need help? Grab the code from the <a href="https://github.com/mjhea0/microservice-movies">microservices-movies</a> repo.</p></blockquote>

<p>The movies database image should take much less time to build than the users database. Why?</p>

<p>With the containers up, let&rsquo;s test out the endpoints&hellip;</p>

<table>
<thead>
<tr>
<th> Endpoint      </th>
<th> HTTP Method </th>
<th> CRUD Method </th>
<th> Result                    </th>
</tr>
</thead>
<tbody>
<tr>
<td> /movies/ping  </td>
<td> GET         </td>
<td> READ        </td>
<td> <code>pong</code>                    </td>
</tr>
<tr>
<td> /movies/user  </td>
<td> GET         </td>
<td> READ        </td>
<td> get all movies by user    </td>
</tr>
<tr>
<td> /movies       </td>
<td> POST        </td>
<td> CREATE      </td>
<td> add a single movie        </td>
</tr>
</tbody>
</table>


<p>Start with opening the browser to <a href="http://localhost:3001/movies/ping">http://localhost:3001/movies/ping</a>. You should see <code>pong</code>! Try <a href="http://localhost:3001/movies/user">http://localhost:3001/movies/user</a>:</p>

<pre><code class="json">{
  "status": "Please log in"
}
</code></pre>

<p>Since you need to be authenticated to access the other routes, let&rsquo;s test them out by running the integration tests:</p>

<pre><code class="sh">$ docker-compose run movies-service npm test
</code></pre>

<p>You should see:</p>

<pre><code class="sh">routes : index
  GET /does/not/exist
    ✓ should throw an error

Movies API Routes
  GET /movies/ping
    ✓ should return "pong"
  GET /movies/user
    ✓ should return saved movies
  POST /movies
    ✓ should create a new movie


4 passing (818ms)
</code></pre>

<p>Check the test specs for more info.</p>

<h2>Web Service - part 2</h2>

<p>Turn to the <em>docker-compose.yml</em> file. Update the <code>links</code> and <code>depends_on</code> keys for the <code>web-service</code>:</p>

<pre><code>depends_on:
  users-service:
    condition: service_started
  movies-service:
    condition: service_started
links:
  - users-service
  - movies-service
</code></pre>

<p>Why?</p>

<p>Next, update the container:</p>

<pre><code class="sh">$ docker-compose up -d web-service
</code></pre>

<p>Let&rsquo;s test this out in the browser! Open <a href="http://localhost:3007/">http://localhost:3007/</a>. Register a new user and then add some movies to the collection.</p>

<p>Be sure to view the collection as well:</p>

<div style="text-align:center;">
  <img src="http://mherman.org/images/blog/microservice-movies-collection.png" style="max-width: 100%; border:0; box-shadow: none;" alt="collection page">
</div>


<p>Open <em>services/movies/src/routes/_helpers.js</em> and take note of the <code>ensureAuthenticated()</code> method:</p>

<pre><code class="javascript">let ensureAuthenticated = (req, res, next) =&gt; {
  if (!(req.headers &amp;&amp; req.headers.authorization)) {
    return res.status(400).json({ status: 'Please log in' });
  }
  const options = {
    method: 'GET',
    uri: 'http://users-service:3000/users/user',
    json: true,
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${req.headers.authorization.split(' ')[1]}`,
    },
  };
  return request(options)
  .then((response) =&gt; {
    req.user = response.user;
    return next();
  })
  .catch((err) =&gt; { return next(err); });
};
</code></pre>

<p>Why does the uri point to <code>users-service</code> and not <code>localhost</code>?</p>

<h2>Workflow</h2>

<p>Start by checking out the <em>Workflow</em> section from <a href="http://mherman.org/blog/2017/04/18/developing-and-testing-microservices-with-docker/">Developing and Testing Microservices With Docker</a>. Experiment with live reloading on a code change and debugging a running container with <code>console.log</code>.</p>

<p>Add a header to the collection page:</p>

<div style="text-align:center;">
  <img src="http://mherman.org/images/blog/microservice-movies-collection-updated.png" style="max-width: 100%; border:0; box-shadow: none;" alt="collection page with header">
</div>


<p>Run the logs - <code>docker-compose logs -f web-service</code> - and then make a change to one of the components that breaks compilation:</p>

<pre><code class="sh">web-service       | Compiling...
web-service       | Failed to compile.
web-service       |
web-service       | Error in ./src/components/SavedMovies.jsx
web-service       |
web-service       | /usr/src/app/src/components/SavedMovies.jsx
web-service       |   10:13  error  'Link' is not defined  react/jsx-no-undef
web-service       |
web-service       | ✖ 1 problem (1 error, 0 warnings)
web-service       |
web-service       |
</code></pre>

<p>Correct the error:</p>

<pre><code class="sh">web-service       |
web-service       | Compiling...
web-service       | Compiled successfully!
</code></pre>

<p>Continue to experiment with adding and updating the React app until you feel comfortable working with it inside the container.</p>

<h2>Test Setup</h2>

<p>Thus far we&rsquo;ve only tested each individual microservice with unit and integration tests. Let&rsquo;s turn our attention to functional, end-to-end tests to test the entire system. For this, we&rsquo;ll use <a href="https://devexpress.github.io/testcafe/">TestCafe</a>.</p>

<blockquote><p><strong>NOTE:</strong> Don&rsquo;t want to use TestCafe? Check out the <a href="https://github.com/mjhea0/node-docker-api/tree/master/tests">code</a> for using Mocha, Chai, Request, and Cheerio (all within a container) for testing.</p></blockquote>

<p>Let&rsquo;s be lazy and install TestCafe globally:</p>

<pre><code class="sh">$ npm install testcafe@0.15.0 -g
</code></pre>

<p>Then run the tests:</p>

<pre><code class="sh">$ testcafe firefox tests/**/*.js
</code></pre>

<p>You should see:</p>

<pre><code class="sh">testcafe firefox tests/**/*.js
 Running tests in:
 - Firefox 53.0.0 / Mac OS X 10.11.0

 /login
 ✓ users should be able to log in and out


 1 passed (3s)
</code></pre>

<blockquote><p><strong>NOTE:</strong> Interested in running the tests from within a container? Check out the <a href="https://devexpress.github.io/testcafe/documentation/using-testcafe/installing-testcafe.html#using-testcafe-docker-image">official TestCafe docs</a> for more info on using TestCafe with Docker.</p></blockquote>

<p>To simplify the test workflow, add a <em>test.sh</em> file to the project root:</p>

<pre><code class="sh">#!/bin/bash

fails=''

inspect() {
  if [ $1 -ne 0 ] ; then
    fails="${fails} $2"
  fi
}

docker-compose run users-service npm test
inspect $? users-service

docker-compose run movies-service npm test
inspect $? movies-service

testcafe firefox tests/**/*.js
inspect $? e2e

if [ -n "${fails}" ];
  then
    echo "Tests failed: ${fails}"
    exit 1
  else
    echo "Tests passed!"
    exit 0
fi
</code></pre>

<p>Run the tests:</p>

<pre><code class="sh">$ sh test.sh
</code></pre>

<h2>Swagger Setup</h2>

<p>Add a <em>Dockerfile</em> to &ldquo;services/movies/swagger&rdquo;:</p>

<pre><code>FROM node:latest

# set working directory
RUN mkdir /usr/src/app
WORKDIR /usr/src/app

# add `/usr/src/node_modules/.bin` to $PATH
ENV PATH /usr/src/app/node_modules/.bin:$PATH

# install and cache app dependencies
ADD package.json /usr/src/app/package.json
RUN npm install

# start app
CMD ["npm", "start"]
</code></pre>

<p>Update <em>docker-compose.yml</em>:</p>

<pre><code>swagger:
  container_name: swagger
  build: ./services/movies/swagger/
  volumes:
    - './services/movies/swagger:/usr/src/app'
    - '/usr/src/app/node_modules'
  ports:
    - '3003:3001' # expose ports - HOST:CONTAINER
  environment:
    - NODE_ENV=${NODE_ENV}
  depends_on:
    users-service:
      condition: service_started
    movies-service:
      condition: service_started
  links:
    - users-service
    - movies-service
</code></pre>

<p>Fire it up:</p>

<pre><code class="sh">$ docker-compose up -d --build swagger
</code></pre>

<p>Navigate to <a href="http://localhost:3003/docs">http://localhost:3003/docs</a> and test it out:</p>

<div style="text-align:center;">
  <img src="http://mherman.org/images/blog/microservice-movies-swagger.png" style="max-width: 100%; border:0; box-shadow: none;" alt="swagger docs">
</div>


<p>Now you just need to incorporate support for JWT-based auth and add the remaining endpoints!</p>

<h2>Next Steps</h2>

<p>What&rsquo;s next?</p>

<ol>
<li><em>React App</em> - The React app could use some love. Add styles. Fix bugs. Update the flash messages so that only one is displayed at a time. Write tests. Build new features. Add Redux. The sky&rsquo;s the limit. Contact me if you&rsquo;d like to pair!</li>
<li><em>Swagger</em> - Add JWT-based auth and add additional endpoints from the movies service.</li>
<li><em>Dockerfiles</em> - Read <a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/">Best practices for writing Dockerfiles</a>, by the Docker team, and refactor as necessary.</li>
</ol>


<p>Grab the final code from the <a href="https://github.com/mjhea0/microservice-movies">microservice-movies</a> repo. Please add questions and/or comments below. There’s slides too! Check them out <a href="http://mherman.org/microservice-movies">here</a>, if interested.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Flask for Node Developers]]></title>
    <link href="http://mherman.org/blog/2017/04/26/flask-for-node-developers/"/>
    <updated>2017-04-26T08:46:05-06:00</updated>
    <id>http://mherman.org/blog/2017/04/26/flask-for-node-developers</id>
    <content type="html"><![CDATA[<p><strong>Today we&rsquo;ll be going through how to build a basic CRUD server-side application using Python and <a href="http://flask.pocoo.org/">Flask</a>, geared toward JavaScript developers versed in Node and Express</strong>. Similar to <a href="https://expressjs.com/">Express</a>, <a href="http://flask.pocoo.org/">Flask</a> is a simple, yet powerful micro-framework for Python, perfect for RESTful APIs.</p>

<div style="text-align:center;">
  <img src="http://mherman.org/images/blog/flask-node.png" style="max-width: 100%; border:0; box-shadow: none;" alt="flask and node">
</div>


<p><br></p>

<blockquote><p>This tutorial uses Flask v<a href="https://pypi.python.org/pypi/Flask/0.12.1">0.12.1</a> and Python v<a href="https://www.python.org/downloads/release/python-361/">3.6.1</a>.</p></blockquote>

<h2>Contents</h2>

<ol>
<li>Objectives</li>
<li>Project Setup</li>
<li>Database Setup</li>
<li>Routes</li>
<li>Next Steps</li>
</ol>


<h2>Objectives</h2>

<p>By the end of this tutorial, you should be able to&hellip;</p>

<ol>
<li>Set up a Python development environment</li>
<li>Create and activate a virtual environment</li>
<li>Using SQLite, apply a schema to the database and interact with the database using the basic CRUD functions</li>
<li>Build a CRUD app using Python and Flask</li>
</ol>


<h2>Project Setup</h2>

<p>Before we start, ensure that you have <a href="https://www.python.org/downloads/release/python-361/">Python v3.6.1</a> installed.</p>

<p>Along with Python, we also need <a href="https://pypi.python.org/pypi/pip">pip</a> to install third-party packages from the <a href="https://pypi.python.org/pypi">Python Package Index</a> (aka PyPI), the Python equivalent of npm. Fortunately, this comes pre-installed with all Python versions >= 3.4.</p>

<p>Let&rsquo;s start by creating a new project directory:</p>

<pre><code class="sh">$ mkdir flask-songs-api &amp;&amp; cd flask-songs-api
</code></pre>

<p>Next up, we&rsquo;ll create an isolated virtual environment for installing Python packages specific to our individual project. It&rsquo;s <a href="https://www.python.org/dev/peps/pep-0405/#isolation-from-system-site-packages">standard practice</a> to set up a virtual environment for each project, otherwise there can be compatibility issues with different dependencies.</p>

<pre><code class="sh">$ python3.6 -m venv env
</code></pre>

<p>Next, we need to activate it:</p>

<pre><code class="sh">$ source env/bin/activate
</code></pre>

<p>You should now see <code>env</code> in your prompt, indicating that the virtual environment is activated.</p>

<blockquote><p><strong>NOTE:</strong> Ready to stop developing? Use the <code>deactivate</code> command to deactivate the virtual environment. To activate it again, navigate to the directory and re-run the source command - <code>source env/bin/activate</code>.</p></blockquote>

<p>Now we can install Flask:</p>

<pre><code class="sh">$ pip install Flask==0.12.1
$ pip freeze &gt; requirements.txt
</code></pre>

<p>Now is a great time to add a <em>.gitignore</em>:</p>

<pre><code>env
*.db
</code></pre>

<p>Finally, let&rsquo;s add a main app file, which will handle routing and run our application, along with a file to setup our database schema:</p>

<pre><code class="sh">$ touch app.py models.py
</code></pre>

<h2>Database Setup</h2>

<p>For this tutorial, we will be using <a href="https://www.sqlite.org/">SQLite3</a> since it&rsquo;s part of the <a href="https://docs.python.org/3.5/library/sqlite3.html">Python standard library</a>, requires little (if any) configuration, and is powerful enough for small to mid-size applications (e.g., the majority of web apps).</p>

<p>Start by creating a new database file in your project root:</p>

<pre><code class="sh">$ touch songs.db
</code></pre>

<p>Now start a new SQLite session:</p>

<pre><code class="sh">$ sqlite3 songs.db
</code></pre>

<p>Then run:</p>

<pre><code class="sh">sqlite&gt; .databases
</code></pre>

<p>You should see a file path to your database file, which is empty at the moment and ready for us to create a schema and data to. To create a schema, add the following code to <em>models.py</em>:</p>

<pre><code class="python">import sqlite3


def drop_table():
    with sqlite3.connect('songs.db') as connection:
        c = connection.cursor()
        c.execute("""DROP TABLE IF EXISTS songs;""")
    return True


def create_db():
    with sqlite3.connect('songs.db') as connection:
        c = connection.cursor()
        table = """CREATE TABLE songs(
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            artist TEXT NOT NULL,
            title TEXT NOT NULL,
            rating INTEGER NOT NULL
        );
        """
        c.execute(table)
    return True


if __name__ == '__main__':
    drop_table()
    create_db()
</code></pre>

<p>This will drop the songs table if it exists and put a new one in place with the schema we&rsquo;ve defined here. If you have any issues with your database later on, or if you just want to start fresh, you can always run this script to recreate the database. Back in the terminal, exit SQLite and then run the script to create our table:</p>

<pre><code class="sh">sqlite&gt; .exit
$ python models.py
</code></pre>

<p>Let&rsquo;s check if that actually worked:</p>

<pre><code class="sh">$ sqlite3 songs.db
sqlite&gt; .table
songs
sqlite&gt; .schema
CREATE TABLE songs(
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            artist TEXT NOT NULL,
            title TEXT NOT NULL,
            rating INTEGER NOT NULL
        );
sqlite&gt; .exit
</code></pre>

<p>Great! So, now that our database is set up correctly, we can move on to setting up our app&rsquo;s route handlers. For this post, we won&rsquo;t be going into database migrations but if you ever want to change the schema, you can use <a href="https://flask-migrate.readthedocs.io/en/latest/">Flask-Migrate</a>.</p>

<h2>Routes</h2>

<p>Let&rsquo;s start with an overview of the routes, following RESTful principles:</p>

<table>
<thead>
<tr>
<th> Endpoint              </th>
<th> Result                </th>
<th> CRUD   </th>
<th> HTTP   </th>
</tr>
</thead>
<tbody>
<tr>
<td> <code>/api/songs</code>          </td>
<td> Returns all songs     </td>
<td> Read   </td>
<td> GET    </td>
</tr>
<tr>
<td> <code>/api/song/&lt;song_id&gt;</code> </td>
<td> Returns a single song </td>
<td> Read   </td>
<td> GET    </td>
</tr>
<tr>
<td> <code>/api/songs</code>          </td>
<td> Adds a single song    </td>
<td> Create </td>
<td> POST   </td>
</tr>
<tr>
<td> <code>/api/song/&lt;song_id&gt;</code> </td>
<td> Updates a single song </td>
<td> Update </td>
<td> PUT    </td>
</tr>
<tr>
<td> <code>/api/song/&lt;song_id&gt;</code> </td>
<td> Deletes a single song </td>
<td> Delete </td>
<td> DELETE </td>
</tr>
</tbody>
</table>


<p>But first, before creating any routes, add the following code to <em>app.py</em>:</p>

<pre><code class="python">import sqlite3
from flask import Flask


app = Flask(__name__)


if __name__ == '__main__':
    app.debug = True
    app.run()
</code></pre>

<p>Here we imported <code>sqlite3</code> along with the main <a href="http://flask.pocoo.org/docs/0.12/api/#application-object">Flask application object</a>, <code>Flask</code>, which creates an instance of Flask in our application. The Flask application object acts as the central object, which we can use as a way of calling our view functions, adding our URL rules, template configuration and much more. With that instance we can run the application using the <code>run</code> <a href="http://flask.pocoo.org/docs/0.12/api/#flask.Flask.run">method</a>. We also set the <a href="http://flask.pocoo.org/docs/0.12/api/#flask.Flask.debug">debug flag</a> to <code>True</code> so that the server live reloads when code changes and provides an interactive debugger when an exception is thrown.</p>

<blockquote><p><strong>NOTE:</strong> <code>if __name__ == '__main__'</code> states that this source file is our main program. Any files imported from other modules will have their name set to their module name. This is because you may sometimes have modules that could be executed directly as well as be imported into a main app file. This line means that the code in those modules will only execute when you want to run the module as a program, and not have it execute when someone just wants to import a module and execute it themselves.</p></blockquote>

<p>Finally, it&rsquo;s important to note that any imports must go at the top of our <em>app.py</em> file. These must come before anything else in order to be used later on in our file.</p>

<p>Now, add the routes:</p>

<pre><code class="python">import sqlite3
from flask import Flask, request


app = Flask(__name__)


@app.route('/api/songs', methods=['GET', 'POST'])
def collection():
    if request.method == 'GET':
        pass  # Handle GET all Request
    elif request.method == 'POST':
        pass  # Handle POST request


@app.route('/api/song/&lt;song_id&gt;', methods=['GET', 'PUT', 'DELETE'])
def resource(song_id):
    if request.method == 'GET':
        pass  # Handle GET single request
    elif request.method == 'PUT':
        pass  # Handle UPDATE request
    elif request.method == 'DELETE':
        pass  # Handle DELETE request


if __name__ == '__main__':
    app.debug = True
    app.run()
</code></pre>

<p>We imported <code>request</code>, which handles, well, HTTP requests (no surprises there). Let&rsquo;s look at each method, staring with a POST:</p>

<h3>POST</h3>

<p>The first thing we need to do is add data to our database. Once we&rsquo;ve done this, we can start building and testing the rest of our database/CRUD functions.</p>

<p>The process is simple:</p>

<ol>
<li>Create a connection to our database</li>
<li>Execute our SQL query to add a song</li>
<li>Commit the changes to the database</li>
<li>Close the database connection</li>
<li>Return an object</li>
</ol>


<p>We can write a single function to handle this. Let&rsquo;s place all helper functions underneath the routes, to keep things nicely separated:</p>

<pre><code class="python"># helper functions

def add_song(artist, title, rating):
    try:
        with sqlite3.connect('songs.db') as connection:
            cursor = connection.cursor()
            cursor.execute("""
                INSERT INTO songs (artist, title, rating) values (?, ?, ?);
                """, (artist, title, rating,))
            result = {'status': 1, 'message': 'Song Added'}
    except:
        result = {'status': 0, 'message': 'error'}
    return result
</code></pre>

<p>Now we can just use this function in our route handler, passing the correct arguments from an incoming POST request:</p>

<pre><code class="python">@app.route('/api/songs', methods=['GET', 'POST'])
def collection():
    if request.method == 'GET':
        pass  # Handle GET all Request
    elif request.method == 'POST':
        data = request.form
        result = add_song(data['artist'], data['title'], data['rating'])
        return jsonify(result)
</code></pre>

<p>So, we grabbed the values from the incoming form request, then called the <code>add_song()</code> function to add that song to the database, and, finally, returned the appropriate JSON response.</p>

<p>Make sure to add <code>jsonify</code> to the imports in order to send a JSON response back:</p>

<pre><code class="python">from flask import Flask, request, jsonify
</code></pre>

<p>Ready to test? Start the server in one terminal window:</p>

<pre><code class="sh">$ python app.py
</code></pre>

<p>Now, in another window use CURL to send a POST request:</p>

<pre><code class="sh">$ curl --data "artist='Hudson Mohawke'&amp;title='Cbat'&amp;rating=5" http://localhost:5000/api/songs
</code></pre>

<p>If all went well, you should see the follwing response, indicating that the song was added to the database:</p>

<pre><code class="sh">{
  "message": "Song Added",
  "status": 1
}
</code></pre>

<p>Just to be on the safe side, let&rsquo;s double-check that. Kill the server, then open a SQLite session from within your project directory:</p>

<pre><code class="sh">$ sqlite3 songs.db
</code></pre>

<p>Now run the following SQL query:</p>

<pre><code class="sh">sqlite&gt; SELECT * FROM songs ORDER BY id desc;
</code></pre>

<p>You should see:</p>

<pre><code>1|'Hudson Mohawke'|'Cbat'|5`
</code></pre>

<p>Okay. We have officially added our first song! Add a couple more before moving on to reading data (GET). Don&rsquo;t forget to run the Flask server before running the CURL commands!</p>

<pre><code class="sh">$ curl --data "artist='Beastie Boys'&amp;title='Sabotage'&amp;rating=4" http://localhost:5000/api/songs
$ curl --data "artist='Gregori Klosman'&amp;title='Jaws'&amp;rating=3" http://localhost:5000/api/songs
</code></pre>

<h3>GET</h3>

<p>We&rsquo;ll start with our GET all route, e.g. - <code>api/songs</code>. We need to connect to the database, execute the appropriate SQL query, and then return all of the songs from that query:</p>

<pre><code class="python">def get_all_songs():
    with sqlite3.connect('songs.db') as connection:
        cursor = connection.cursor()
        cursor.execute("SELECT * FROM songs ORDER BY id desc")
        all_songs = cursor.fetchall()
        return all_songs
</code></pre>

<p>Next up, we have to change our route handler to now call this function and then send back JSON:</p>

<pre><code class="python">@app.route('/api/songs', methods=['GET', 'POST'])
def collection():
    if request.method == 'GET':
        all_songs = get_all_songs()
        return json.dumps(all_songs)
    elif request.method == 'POST':
        data = request.form
        result = add_song(data['artist'], data['title'], data['rating'])
        return jsonify(result)
</code></pre>

<p>Did you notice that we&rsquo;re using the <code>json</code> module? This is also from the Python standard library, which allows us to convert the &lsquo;list&rsquo;-like format of data we get back from SQLite3 into a JSON object. Just don&rsquo;t forget to import it:</p>

<pre><code class="python">import json
</code></pre>

<p>To test, we can simply navigate to <a href="http://127.0.0.1:5000/api/songs">http://127.0.0.1:5000/api/songs</a> in the browser to check if all our songs are there.</p>

<p>You should see something like:</p>

<pre><code class="json">[
  [
    3,
    "'Gregori Klosman'",
    "'Jaws'",
    3
  ],
  [
    2,
    "'Beastie Boys'",
    "'Sabotage'",
    4
  ],
  [
    1,
    "'Hudson Mohawke'",
    "'Cbat'",
    5
  ]
]
</code></pre>

<p>Now that we can GET all songs, let&rsquo;s build a function to GET just a single song. This function will take a parameter of <code>song_id</code>, create a connection to our database, find that song with a SQL query, and then return that song with JSON:</p>

<pre><code class="python">def get_single_song(song_id):
    with sqlite3.connect('songs.db') as connection:
        cursor = connection.cursor()
        cursor.execute("SELECT * FROM songs WHERE id = ?", (song_id,))
        song = cursor.fetchone()
        return song
</code></pre>

<p>We can update our route with a <code>song_id</code> as a parameter, and send back the single song:</p>

<pre><code class="py">@app.route('/api/song/&lt;song_id&gt;', methods=['GET', 'PUT', 'DELETE'])
def resource(song_id):
    if request.method == 'GET':
        song = get_single_song(song_id)
        return json.dumps(song)
    elif request.method == 'PUT':
        pass  # Handle UPDATE request
    elif request.method == 'DELETE':
        pass  # Handle DELETE request
</code></pre>

<p>If you now point your browser to <a href="http://127.0.0.1:5000/api/song/2">http://127.0.0.1:5000/api/song/2</a> you should see the JSON object for our song with an id of <code>2</code> in the database:</p>

<pre><code class="json">[
    2,
    "'Beastie Boys'",
    "'Sabotage'",
    4
]
</code></pre>

<p>If you try to put in an id that we don&rsquo;t have in the database currently, you will just get <code>null</code> displayed on the page instead of a JSON object.</p>

<p>We can CREATE a song, READ all songs, and READ a single song. Only two more routes to go&hellip;</p>

<h3>PUT</h3>

<p>A major function that we&rsquo;re missing is the ability to edit data that&rsquo;s already present in our database. We do this using a PUT request by taking incoming data with an id passed through the URL, finding the object in our database with that particular id, and then updating it.</p>

<p>Let&rsquo;s start with an edit function, which takes in the song id, artist, title, and rating as arguments:</p>

<pre><code class="python">def edit_song(song_id, artist, title, rating):
    try:
        with sqlite3.connect('songs.db') as connection:
            connection.execute("UPDATE songs SET artist = ?, title = ?, rating = ? WHERE ID = ?;", (artist, title, rating, song_id,))
            result = {'status': 1, 'message': 'SONG Edited'}
    except:
        result = {'status': 0, 'message': 'Error'}
    return result
</code></pre>

<p>Now we can edit our route to pass in the data from the PUT request:</p>

<pre><code class="py">@app.route('/api/song/&lt;song_id&gt;', methods=['GET', 'PUT', 'DELETE'])
def resource(song_id):
    if request.method == 'GET':
        song = get_single_song(song_id)
        return json.dumps(song)
    elif request.method == 'PUT':
        data = request.form
        result = edit_song(
            song_id, data['artist'], data['title'], data['rating'])
        return jsonify(result)
    elif request.method == 'DELETE':
        pass  # Handle DELETE request
</code></pre>

<p>So if we test this route out with CURL:</p>

<pre><code class="sh">$ curl -X PUT --data "artist='Van Halen'&amp;title='Hot for Teacher'&amp;rating=3" localhost:5000/api/song/2
</code></pre>

<p>We should see:</p>

<pre><code class="sh">{
  "message": "SONG Edited",
  "status": 1
}
</code></pre>

<p>We can (err, should) make sure that edit is reflected in the database:</p>

<pre><code class="sh">$ sqlite3 songs.db
sqlite&gt; SELECT * FROM songs ORDER BY id desc;

3|'Gregori Klosman'|'Jaws'|3
2|'Van Halen'|'Hot for Teacher'|3
1|'Hudson Mohawke'|'Cbat'|5
</code></pre>

<p>We can edit songs at will!</p>

<h3>Delete</h3>

<p>The last thing we have left to do is our DELETE route. We need to be able to remove data from our database. Let&rsquo;s first add in a song we can then delete using CURL in the terminal:</p>

<pre><code class="sh">$ curl --data "artist='The Flaming Lips'&amp;title='Buggin'&amp;rating=2" http://localhost:5000/api/songs
</code></pre>

<p>Make sure it&rsquo;s in our database:</p>

<pre><code class="sh">$ sqlite3 songs.db
sqlite&gt; SELECT * FROM songs ORDER BY id desc;

4|'The Flaming Lips'|'Buggin'|2
3|'Gregori Klosman'|'Jaws'|3
2|'Van Halen'|'Hot for Teacher'|3
1|'Hudson Mohawke'|'Cbat'|5
</code></pre>

<p>We need to build a delete function:</p>

<pre><code class="python">def delete_song(song_id):
    try:
        with sqlite3.connect('songs.db') as connection:
            connection.execute("DELETE FROM songs WHERE ID = ?;", (song_id,))
            result = {'status': 1, 'message': 'SONG Deleted'}
    except:
        result = {'status': 0, 'message': 'Error'}
    return result
</code></pre>

<p>And now let&rsquo;s add in our delete route:</p>

<pre><code class="py">@app.route('/api/song/&lt;song_id&gt;', methods=['GET', 'PUT', 'DELETE'])
def resource(song_id):
    if request.method == 'GET':
        song = get_single_song(song_id)
        return json.dumps(song)
    elif request.method == 'PUT':
        data = request.form
        result = edit_song(
            song_id, data['artist'], data['title'], data['rating'])
        return jsonify(result)
    elif request.method == 'DELETE':
        result = delete_song(song_id)
        return jsonify(result)
</code></pre>

<p>Test it with CURL:</p>

<pre><code class="sh">$ curl -X DELETE localhost:5000/api/song/4

{
  "message": "SONG Deleted",
  "status": 1
}
</code></pre>

<p>And finally, go back into our database and really make sure it&rsquo;s gone:</p>

<pre><code class="sh">$ sqlite3 songs.db
sqlite&gt; SELECT * FROM songs ORDER BY id desc;

3|'Gregori Klosman'|'Jaws'|3
2|'Van Halen'|'Hot for Teacher'|3
1|'Hudson Mohawke'|'Cbat'|5
</code></pre>

<p>Boom! So we now have all of our routes doing <em>exactly</em> what we want them to do. We can add songs, get the songs back (all, or just a single song), edit a song, and remove a song. That&rsquo;s some quality CRUD right there.</p>

<h2>Next Steps</h2>

<ol>
<li><em>Error Handling</em>: The code we have right now is completely reliant on the data coming through correctly, but what if there&rsquo;s something missing when the user sends a POST request? For example, what would happen if the artist name was missing? Right now we aren&rsquo;t handling errors that may come up. Think about how we can send information back to the user if not all fields are present in the POST or PUT request, and how you could be clear in the error messages we send back to the user.</li>
<li><em>Server-side Templating</em>: Build out your client-side by adding <a href="http://flask.pocoo.org/docs/0.12/quickstart/#static-files">static files</a> and <a href="http://flask.pocoo.org/docs/0.12/quickstart/#rendering-templates">templates</a>.</li>
<li><em>Database Management:</em> Refactor SQLite and vanilla SQL out of your application and add in Postgres, <a href="http://flask-sqlalchemy.pocoo.org/2.1/">Flask-SQLAlchemy</a> (for communicating with the database), and <a href="https://flask-migrate.readthedocs.io/en/latest/">Flask-Migrate</a> (for migrations). Check out <a href="https://github.com/mjhea0/flask-songs-api/tree/master/_live">this example</a> of how to use Postgres and Flask-SQLAlchemy.</li>
</ol>


<p>Grab the code from the <a href="https://github.com/mjhea0/flask-songs-api">flask-songs-api</a> repo. Cheers!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Developing and Testing Microservices With Docker]]></title>
    <link href="http://mherman.org/blog/2017/04/18/developing-and-testing-microservices-with-docker/"/>
    <updated>2017-04-18T08:16:46-06:00</updated>
    <id>http://mherman.org/blog/2017/04/18/developing-and-testing-microservices-with-docker</id>
    <content type="html"><![CDATA[<p>Often, when developing applications with a microservice architecture, you cannot fully test out all services until you deploy to a staging server. This takes much too long to get feedback. Docker helps to speed up this process by making it easier to link together small, independent services locally.</p>

<p><strong>In this article we&rsquo;ll look at how to configure and test a number of services locally with <a href="https://docs.docker.com/">Docker</a> and <a href="https://docs.docker.com/compose/">Docker Compose</a>. We&rsquo;ll also look at workflow and how to interact with and debug containers.</strong></p>

<div style="text-align:center;">
  <img src="http://mherman.org/images/blog/node-docker-api.png" style="max-width: 100%; border:0; box-shadow: none;" alt="microservice architecture">
</div>


<p><br></p>

<p>This post assumes prior knowledge of the following topics. Refer to the resources for more info:</p>

<table>
<thead>
<tr>
<th> Topic            </th>
<th> Resource </th>
</tr>
</thead>
<tbody>
<tr>
<td> Docker           </td>
<td> <a href="https://docs.docker.com/engine/getstarted/">Get started with Docker</a> </td>
</tr>
<tr>
<td> Docker Compose   </td>
<td> <a href="https://docs.docker.com/compose/gettingstarted/">Get started with Docker Compose</a> </td>
</tr>
<tr>
<td> Node/Express API </td>
<td> <a href="http://mherman.org/blog/2016/09/12/testing-node-and-express">Testing Node and Express</a> </td>
</tr>
</tbody>
</table>


<blockquote><p><strong>NOTE</strong>: Looking for a more advanced implementation with React? Check out my other post - <a href="http://mherman.org/blog/2017/05/11/developing-microservices-node-react-docker">Developing Microservices - Node, React, and Docker</a>.</p></blockquote>

<h2>Contents</h2>

<ol>
<li>Objectives</li>
<li>Project Setup</li>
<li>Docker Config</li>
<li>Postgres Setup</li>
<li>Users Service Setup</li>
<li>Locations Service Setup</li>
<li>Web Setup</li>
<li>Workflow</li>
<li>Testing</li>
<li>Test Setup</li>
<li>Next Steps</li>
</ol>


<h2>Objectives</h2>

<p>By the end of this tutorial, you should be able to&hellip;</p>

<ol>
<li>Configure and run a set of microservices locally with Docker and Docker Compose</li>
<li>Utilize <a href="https://docs.docker.com/engine/tutorials/dockervolumes/">volumes</a> to mount your code into a container</li>
<li>Run unit and integration tests inside a Docker container</li>
<li>Set up a separate container for functional tests</li>
<li>Debug a running Docker container</li>
<li>Utilize <a href="https://docs.docker.com/compose/compose-file/#links">links</a> for inter-container communication (AJAX)</li>
<li>Secure your services via JWT-based authentication</li>
</ol>


<h2>Project Setup</h2>

<p>Start by cloning the base project and then checking out the first tag:</p>

<pre><code class="sh">$ git clone https://github.com/mjhea0/node-docker-api
$ cd node-docker-api
$ git checkout tags/v1
</code></pre>

<p>Take a quick look at the structure, broken down by service:</p>

<pre><code class="sh">├── services
│   ├── locations
│   │   ├── gulpfile.js
│   │   ├── knexfile.js
│   │   ├── package.json
│   │   ├── src
│   │   │   ├── app.js
│   │   │   ├── db
│   │   │   │   ├── connection.js
│   │   │   │   ├── create.sql
│   │   │   │   ├── migrations
│   │   │   │   │   └── 20170405114746_locations.js
│   │   │   │   ├── queries.js
│   │   │   │   └── seeds
│   │   │   │       └── locations.js
│   │   │   ├── routes
│   │   │   │   ├── _helpers.js
│   │   │   │   └── locations.js
│   │   │   └── server.js
│   │   └── tests
│   │       └── integration
│   │           ├── routes.index.test.js
│   │           └── routes.locations.test.js
│   └── users
│       ├── gulpfile.js
│       ├── knexfile.js
│       ├── npm-debug.log
│       ├── package.json
│       ├── src
│       │   ├── app.js
│       │   ├── auth
│       │   │   ├── _helpers.js
│       │   │   └── local.js
│       │   ├── db
│       │   │   ├── connection.js
│       │   │   ├── create.sql
│       │   │   ├── migrations
│       │   │   │   └── 20170403223908_users.js
│       │   │   └── seeds
│       │   │       └── users.js
│       │   ├── routes
│       │   │   └── users.js
│       │   └── server.js
│       └── tests
│           ├── integration
│           │   ├── routes.index.test.js
│           │   └── routes.users.test.js
│           └── unit
│               ├── auth.helpers.test.js
│               └── auth.local.test.js
├── tests
│   ├── main.test.js
│   └── package.json
└── web
    ├── gulpfile.js
    ├── package.json
    └── src
        ├── app.js
        ├── public
        │   ├── main.css
        │   └── main.js
        ├── routes
        │   ├── _helpers.js
        │   └── index.js
        ├── server.js
        └── views
            ├── _base.html
            ├── error.html
            ├── login.html
            ├── main.html
            ├── nav.html
            ├── register.html
            └── user.html
</code></pre>

<p>Before we Dockerize the services, feel free to test the locations and/or users services&hellip;</p>

<p>Users:</p>

<ol>
<li>Navigate to &ldquo;services/users&rdquo;</li>
<li><code>npm install</code></li>
<li><code>node src/server.js</code></li>
<li>Open <a href="http://localhost:3000/users/ping">http://localhost:3000/users/ping</a> in your browser</li>
</ol>


<p>Locations:</p>

<ol>
<li>Navigate to &ldquo;services/locations&rdquo;</li>
<li><code>npm install</code></li>
<li><code>node src/server.js</code></li>
<li>Open <a href="http://localhost:3001/locations/ping">http://localhost:3001/locations/ping</a> in your browser</li>
</ol>


<p>Kill the servers once done.</p>

<h2>Docker Config</h2>

<p>Add a <em>docker-compose.yml</em> file to the project root, which is a config file used by Docker Compose to link multiple services together:</p>

<pre><code>version: '2.1'
</code></pre>

<blockquote><p><strong>NOTE:</strong> Why 2.1? <a href="https://docs.docker.com/compose/compose-file/compose-file-v2/#version-21">Answer</a>.</p></blockquote>

<p>Then add a <em>.dockerignore</em> to the &ldquo;services/locations&rdquo;, &ldquo;services/locations/src/db&rdquo;, &ldquo;services/users&rdquo;, &ldquo;services/users/src/db&rdquo;, &ldquo;tests&rdquo;, and &ldquo;web&rdquo; directories:</p>

<pre><code>.git
.gitignore
README.md
docker-compose.yml
node_modules
</code></pre>

<p>With that, let&rsquo;s set up each service individually, testing as we go&hellip;</p>

<h2>Postgres Setup</h2>

<p>Add a <em>Dockerfile</em> to &ldquo;services/locations/src/db&rdquo; and &ldquo;services/users/src/db&rdquo;:</p>

<pre><code>FROM postgres

# run create.sql on init
ADD create.sql /docker-entrypoint-initdb.d
</code></pre>

<p>Then update <em>docker-compose.yml</em>:</p>

<pre><code>version: '2.1'

services:

  users-db:
    container_name: users-db
    build: ./services/users/src/db
    ports:
      - '5433:5432'
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=admin
    healthcheck:
      test: exit 0

  locations-db:
    container_name: locations-db
    build: ./services/locations/src/db
    ports:
      - '5434:5432'
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=admin
    healthcheck:
      test: exit 0
</code></pre>

<p>Here, we create two new containers called <code>users-db</code> and <code>locations-db</code>, from the <em>Dockerfiles</em> found in &ldquo;services/users/src/db&rdquo; and &ldquo;services/locations/src/db&rdquo;, respectively. We also add environment variables, expose ports, and send an exit code <code>0</code> once they are successfully up and running - which will be used by other services.</p>

<p>To fire up the containers, run:</p>

<pre><code class="sh">$ docker-compose up --build -d
</code></pre>

<p>Once up, you can get a quick sanity check, by entering the shell:</p>

<pre><code class="sh">$ docker-compose run users-db bash
# exit
$ docker-compose run locations-db bash
# exit
</code></pre>

<h2>Users Service Setup</h2>

<p>Again, add a <em>Dockerfile</em> to &ldquo;services/users&rdquo;, making sure to review the comments:</p>

<pre><code>FROM node:latest

# set working directory
RUN mkdir /src
WORKDIR /src

# install app dependencies
ENV PATH /src/node_modules/.bin:$PATH
ADD package.json /src/package.json
RUN npm install

# start app
CMD ["npm", "start"]
</code></pre>

<p>Add the <code>users-service</code> to the <em>docker-compose.yml</em> file:</p>

<pre><code>users-service:
  container_name: users-service
  build: ./services/users/
  volumes:
    - './services/users:/src/app'
    - './services/users/package.json:/src/package.json'
  ports:
    - '3000:3000'
  environment:
    - DATABASE_URL=postgres://admin:admin@users-db:5432/node_docker_api_users_dev
    - DATABASE_TEST_URL=postgres://admin:admin@users-db:5432/node_docker_api_users_test
    - NODE_ENV=${NODE_ENV}
    - TOKEN_SECRET=changeme
  depends_on:
    users-db:
      condition: service_healthy
  links:
    - users-db
</code></pre>

<p>What&rsquo;s new here?</p>

<ol>
<li><code>volumes</code>: <a href="https://docs.docker.com/engine/tutorials/dockervolumes/">volumes</a> are used to mount a directory into a container so that you can make changes to the code without having to build a new image. This should be a default in your local development environment so you can get quick feedback on code changes.</li>
<li><code>depends_on</code>: <a href="https://docs.docker.com/compose/compose-file/#dependson">depends_on</a> is used to start services in a specific order. So, the <code>users-service</code> will wait for the <code>users-db</code> to fire up successfully (with an exit code of <code>0</code>) before it starts.</li>
<li><code>links</code>: With <a href="https://docs.docker.com/compose/compose-file/#links">links</a>, code inside the <code>users-service</code> can access the database via <code>users-db:5432</code>.</li>
</ol>


<p>Set the <code>NODE_ENV</code> environment variable:</p>

<pre><code class="sh">$ export NODE_ENV=development
</code></pre>

<p>Spin up the container:</p>

<pre><code class="sh">$ docker-compose up --build -d users-service
</code></pre>

<p>Once up, create a new file in the project root called <em>migrate.sh</em> and add the Knex migrate and seed commands:</p>

<pre><code class="sh">#!/bin/sh

docker-compose run users-service knex migrate:latest --env development --knexfile app/knexfile.js
docker-compose run users-service knex seed:run --env development --knexfile app/knexfile.js
</code></pre>

<p>Then run it:</p>

<pre><code class="sh">$ sh migrate.sh
</code></pre>

<p>Test:</p>

<table>
<thead>
<tr>
<th> Endpoint        </th>
<th> HTTP Method </th>
<th> CRUD Method </th>
<th> Result        </th>
</tr>
</thead>
<tbody>
<tr>
<td> /users/ping     </td>
<td> GET         </td>
<td> READ        </td>
<td> <code>pong</code>        </td>
</tr>
<tr>
<td> /users/register </td>
<td> POST        </td>
<td> CREATE      </td>
<td> add a user    </td>
</tr>
<tr>
<td> /users/login    </td>
<td> POST        </td>
<td> CREATE      </td>
<td> log in a user </td>
</tr>
<tr>
<td> /users/user     </td>
<td> GET         </td>
<td> READ        </td>
<td> get user info </td>
</tr>
</tbody>
</table>


<pre><code class="sh">$ http POST http://localhost:3000/users/register username=michael password=herman
$ http POST http://localhost:3000/users/login username=michael password=herman
</code></pre>

<blockquote><p><strong>NOTE:</strong> <code>http</code> in the above commands is part of the <a href="https://httpie.org/">HTTPie</a> library, which is a wrapper on top of cURL.</p></blockquote>

<h2>Locations Service Setup</h2>

<p>Add the <em>Dockerfile</em>:</p>

<pre><code>FROM node:latest

# set working directory
RUN mkdir /src
WORKDIR /src

# install app dependencies
ENV PATH /src/node_modules/.bin:$PATH
ADD package.json /src/package.json
RUN npm install

# start app
CMD ["npm", "start"]
</code></pre>

<p>Add the service to <em>docker-compose</em>:</p>

<pre><code>locations-service:
  container_name: locations-service
  build: ./services/locations/
  volumes:
    - './services/locations:/src/app'
    - './services/locations/package.json:/src/package.json'
  ports:
    - '3001:3001'
  environment:
    - DATABASE_URL=postgres://admin:admin@locations-db:5432/node_docker_api_locations_dev     
    - DATABASE_TEST_URL=postgres://admin:admin@locations-db:5432/node_docker_api_locations_test
    - NODE_ENV=${NODE_ENV}
    - TOKEN_SECRET=changeme
    - OPENWEATHERMAP_API_KEY=${OPENWEATHERMAP_API_KEY}
  depends_on:
    locations-db:
      condition: service_healthy
    users-service:
      condition: service_started
  links:
    - locations-db
    - users-service
</code></pre>

<p>Register with the <a href="https://openweathermap.org/api">OpenWeatherMap API</a>, and add the key as an environment variable:</p>

<pre><code class="sh">$ export OPENWEATHERMAP_API_KEY=YOUR_KEY_HERE
</code></pre>

<p>Spin up the container:</p>

<pre><code class="sh">$ docker-compose up --build -d locations-service
</code></pre>

<p>Add the migrate and seed commands to <em>migrate.sh</em>:</p>

<pre><code class="sh">docker-compose run locations-service knex migrate:latest --env development --knexfile app/knexfile.js
docker-compose run locations-service knex seed:run --env development --knexfile app/knexfile.js
</code></pre>

<p>Run it:</p>

<pre><code class="sh">$ sh migrate.sh
</code></pre>

<p>Test:</p>

<table>
<thead>
<tr>
<th> Endpoint         </th>
<th> HTTP Method </th>
<th> CRUD Method </th>
<th> Result                    </th>
</tr>
</thead>
<tbody>
<tr>
<td> /locations/ping  </td>
<td> GET         </td>
<td> READ        </td>
<td> <code>pong</code>                    </td>
</tr>
<tr>
<td> /locations       </td>
<td> GET         </td>
<td> READ        </td>
<td> get all locations         </td>
</tr>
<tr>
<td> /locations/user  </td>
<td> GET         </td>
<td> READ        </td>
<td> get all locations by user </td>
</tr>
<tr>
<td> /locations/:id   </td>
<td> GET         </td>
<td> READ        </td>
<td> get a single location     </td>
</tr>
<tr>
<td> /locations       </td>
<td> POST        </td>
<td> CREATE      </td>
<td> add a single location     </td>
</tr>
<tr>
<td> /locations/:id   </td>
<td> PUT         </td>
<td> UPDATE      </td>
<td> update a single location  </td>
</tr>
<tr>
<td> /locations/:id   </td>
<td> DELETE      </td>
<td> DELETE      </td>
<td> delete a single location  </td>
</tr>
</tbody>
</table>


<pre><code class="sh">$ http GET http://localhost:3001/locations/ping
</code></pre>

<h2>Web Services Setup</h2>

<p>Moving right along&hellip;</p>

<p>Add the <em>Dockerfile</em>:</p>

<pre><code>FROM node:latest

# set working directory
RUN mkdir /src
WORKDIR /src

# install app dependencies
ENV PATH /src/node_modules/.bin:$PATH
ADD package.json /src/package.json
RUN npm install

# start app
CMD ["npm", "start"]
</code></pre>

<p>Add the service to <em>docker-compose</em>:</p>

<pre><code>web:
  container_name: web
  build: ./web/
  volumes:
    - './web:/src/app'
    - './web/package.json:/src/package.json'
  ports:
    - '3003:3003'
  environment:
    - NODE_ENV=${NODE_ENV}
    - SECRET_KEY=changeme
  depends_on:
    users-service:
      condition: service_started
    locations-service:
      condition: service_started
  links:
    - users-service
    - locations-service
</code></pre>

<p>Spin up the container:</p>

<pre><code class="sh">$ docker-compose up --build -d web
</code></pre>

<p>Navigate to <a href="http://localhost:3003">http://localhost:3003</a> in your browser and you should see the login page. Register a new user. Once redirected, you should see:</p>

<div style="text-align:center;">
  <img src="http://mherman.org/images/blog/node-docker-api-browser.png" style="max-width: 100%; border:0; box-shadow: none;" alt="node docker browser view">
</div>


<p><br></p>

<p>Take a look at the AJAX request in the GET <code>/</code> route in <em>web/src/routes/index.js</em>. Why does the <code>uri</code> point to <code>locations-service</code> and not <code>localhost</code>? Well, <code>localhost</code> refers back to the container itself, so you need to set up a <a href="https://docs.docker.com/compose/compose-file/#links">link</a> in the Docker compose - which we&rsquo;ve already done.</p>

<h2>Testing</h2>

<p>Did you notice the unit and integration tests in the &ldquo;services/users/tests&rdquo; and &ldquo;services/locations/tests&rdquo; folders? Well, to run the tests properly, we need to update the <code>NODE_ENV</code> environment variable, since it is currently configured for the development environment.</p>

<pre><code class="sh">$ export NODE_ENV=test
</code></pre>

<p>Update the containers:</p>

<pre><code class="sh">$ docker-compose up -d
</code></pre>

<p>Then run the tests:</p>

<pre><code class="sh">$ docker-compose run users-service npm test
$ docker-compose run locations-service npm test
</code></pre>

<p>Ready to develop again?</p>

<ol>
<li>Update the env variable - <code>export NODE_ENV=development</code></li>
<li>Update the containers - <code>docker-compose up -d</code></li>
</ol>


<h2>Workflow</h2>

<p>Let&rsquo;s quickly look at how to work with code inside the containers&hellip;</p>

<ol>
<li>Live Reloading - Since the code is mounted in the container via a volume, you can make changes to the local code base which will be applied to the code in the container. <a href="https://github.com/remy/nodemon">Nodemon</a> is used (along with Gulp) to restart the app when changes occur.</li>
<li>Debugging - <code>console.log</code> can be used for testing and debugging. Simply add one to your code base and then open the logs&hellip;</li>
<li>Logs - run <code>docker-compose logs -f</code> to view the logs.</li>
</ol>


<blockquote><p><strong>NOTE:</strong> Check out the <a href="https://github.com/mjhea0/node-docker-api">repo</a> to view more commands.</p></blockquote>

<p>Try it out:</p>

<ol>
<li>Run <code>docker-compose logs -f</code> in the terminal</li>
<li>Add <code>console.log('here');</code> to the top of <em>web/src/routes/index.js</em></li>
<li><p>As soon as you save, you should see the following in the terminal:</p>

<pre><code class="`sh"> web  | [18:35:37] [nodemon] restarting due to changes...
 web  | [18:35:37] [nodemon] running tasks...
 web  | [18:35:39] Using gulpfile /src/app/gulpfile.js
 web  | [18:35:39] Starting 'lint'...
 web  | [18:35:40]
 web  | /src/app/src/routes/index.js
 web  |   1:1  warning  Unexpected console statement  no-console
 web  |
 web  | ✖ 1 problem (0 errors, 1 warning)
 web  |
 web  | [18:35:40] Finished 'lint' after 1.69 s
 web  | [18:35:40] [nodemon] starting `node ./src/server`
 web  | here
</code></pre>

<p> Essentially, Nodemon detected changes and restarted the app, which fired the linter and then the server fired back up.</p></li>
</ol>


<h2>Test Setup</h2>

<p>Finally, to set up the last service, add the <em>Dockerfile</em> to the &ldquo;tests&rdquo; folder:</p>

<pre><code>FROM node:latest

# set working directory
RUN mkdir /src
WORKDIR /src

# install app dependencies
ENV PATH /src/node_modules/.bin:$PATH
ADD package.json /src/package.json
RUN npm install
</code></pre>

<p>Then update the <em>docker-compose.yml</em> file:</p>

<pre><code>tests:
  container_name: tests
  build: ./tests/
  volumes:
    - './tests:/src/app'
    - './tests/package.json:/src/package.json'
  depends_on:
    users-service:
      condition: service_started
    locations-service:
      condition: service_started
  links:
    - users-service
    - locations-service
    - web
</code></pre>

<p>Fire up the container:</p>

<pre><code class="sh">$ docker-compose up --build -d tests
</code></pre>

<p>Update the environment variable, update the containers, and then run the tests:</p>

<pre><code class="sh">$ export NODE_ENV=test
$ docker-compose up -d
$ docker-compose run tests npm test
</code></pre>

<h2>Next Steps</h2>

<p>What&rsquo;s next?</p>

<ol>
<li><strong>Dependency management</strong>: Right now we&rsquo;re installing many of the same dependencies over and over again, in multiple containers. How can we manage this better to spin up new containers faster and save disc space? How about a data-only container that just houses dependencies?</li>
<li><strong>Deployment prep</strong>: Set up Docker Machine for spinning up Docker environments, nginx for load balancing, and Consul for service discovery. Update the environment variables for the base URL since these will be different in production. Add an image registry solution and a data-only container for piping logs to&hellip;</li>
<li><strong>Error handling</strong>: Right now errors are being thrown, but there really isn&rsquo;t much info in the response as to why, which makes debugging difficult. Be a good citizen and handle your errors properly since you may not always have access to the code base from a different service.</li>
<li><strong>DRY</strong>: The code could be refactored in places, especially the tests.</li>
</ol>


<p>Grab the final code from the <a href="https://github.com/mjhea0/node-docker-api">node-docker-api</a> repo. Comment below. Cheers!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Functional Testing With TestCafe]]></title>
    <link href="http://mherman.org/blog/2017/03/19/functional-testing-with-testcafe/"/>
    <updated>2017-03-19T16:37:53-06:00</updated>
    <id>http://mherman.org/blog/2017/03/19/functional-testing-with-testcafe</id>
    <content type="html"><![CDATA[<p>Today we are going to dive into the world of functional web testing with <a href="https://devexpress.github.io/testcafe/">TestCafe</a>.</p>

<p>Unlike the majority of other end-to-end (e2e) testing tools, TestCafe is not dependent on Selenium or WebDriver. Instead, it injects scripts into the browser to communicate directly with the DOM and handle events. It works on any modern browser that supports HTML5 without any plugins. Further, it supports all major operating systems and can run simultaneously on multiple browsers and machines.</p>

<p>We will be using:</p>

<ul>
<li>TestCafe v<a href="https://github.com/DevExpress/testcafe/releases/tag/v0.13.0">0.13.0</a></li>
<li>Chrome v<a href="https://chromereleases.googleblog.com/2017/03/stable-channel-update-for-desktop.html">57</a></li>
<li>NodeJS v<a href="https://nodejs.org/docs/v7.6.0/api/all.html">7.6.0</a></li>
</ul>


<p>Please review the <a href="http://devexpress.github.io/testcafe/documentation/getting-started/">Getting Started</a> guide before beginning.</p>

<h2>Contents</h2>

<ol>
<li>Objectives</li>
<li>Project Setup</li>
<li>Writing Tests</li>
<li>Browser Support</li>
<li>Continuous Integration</li>
<li>Next Steps</li>
</ol>


<h2>Objectives</h2>

<p>By the end of this tutorial, you should be able to&hellip;</p>

<ol>
<li>Set up TestCafe with an existing Node app</li>
<li>Write TestCafe tests using the <a href="https://martinfowler.com/bliki/PageObject.html">PageObject</a> pattern</li>
<li>Test a Node application with functional tests</li>
<li>Integrate TestCafe into a continuous integration process</li>
<li>Configure TestCafe to work with a headless browser</li>
</ol>


<h2>Project Setup</h2>

<p>Start by cloning the base project structure:</p>

<pre><code class="sh">$ git clone https://github.com/mjhea0/testcafe-example --branch v1 --single-branch -b master
</code></pre>

<p>Install the dependencies, and then fire up the app by running <code>npm start</code> to make sure all is well. Navigate to <a href="http://localhost:3000/">http://localhost:3000/</a> in your browser and you should see a list of jobs in HTML. Experiment with the app. Add a job. Update a job. Delete a job. This is what we will be testing. Kill the server when done.</p>

<div style="text-align:center;">
  <img src="http://mherman.org/images/blog/node-jobs.png" style="max-width: 100%; border:0; box-shadow: none;" alt="node jobs">
</div>


<p>Install TestCafe:</p>

<pre><code class="sh">$ npm install testcafe@0.13.0 --save-dev
</code></pre>

<p>With that, you can start running tests.</p>

<blockquote><p><strong>NOTE:</strong> If you were using a Selenium-based testing tool you would need to install both Selenium and Web Driver, which can be difficult depending on your system setup.</p></blockquote>

<p>Add a <code>test</code> command to the <code>scripts</code> in <em>package.json</em>:</p>

<pre><code class="json">"scripts": {
  "start": "node ./bin/www",
  "test": "node_modules/testcafe/bin/testcafe.js chrome tests/"
},
</code></pre>

<p>Here, we specified the path to TestCafe in our &ldquo;node_modules&rdquo; folder along with a <a href="http://devexpress.github.io/testcafe/documentation/using-testcafe/command-line-interface.html#browser-list">target browser</a>, <code>chrome</code>, and a  <a href="http://devexpress.github.io/testcafe/documentation/using-testcafe/command-line-interface.html#file-pathglob-pattern">path</a> to where all tests will be located, <code>tests/</code>.</p>

<p>Now, you can use <code>npm test</code> to run TestCafe.</p>

<p>Let&rsquo;s get a test set up. Add a &ldquo;tests&rdquo; folder to the project root, and add an <em>index.js</em> file to it:</p>

<pre><code class="javascript">import { Selector } from 'testcafe';

fixture('Getting Started')
  .page('https://github.com');

test('Find "testcafe-example" repo on GitHub', async (t) =&gt; {
  const repo = Selector('.repo-list &gt; li &gt; div');
  // search github
  await t
    .typeText('form[action="/search"]', 'testcafe-example user:mjhea0')
    .pressKey('enter');
  // check li for results
  await t
    .expect(repo.innerText).contains('mjhea0/testcafe-example');
});
</code></pre>

<p>What&rsquo;s happening?</p>

<ol>
<li>Since <em>all</em> tests are organized into <a href="http://devexpress.github.io/testcafe/documentation/test-api/test-code-structure.html#fixtures">fixtures</a>, we started with a <code>fixture()</code> function.</li>
<li>Next, we specified a start URL - <code>http://devexpress.github.io/testcafe/example</code> - via the <code>page()</code> <a href="http://devexpress.github.io/testcafe/documentation/test-api/test-code-structure.html#specifying-the-start-webpage">method</a>.</li>
<li>From there, we added the test code into a <code>test()</code> <a href="http://devexpress.github.io/testcafe/documentation/test-api/test-code-structure.html#tests">function</a>, which takes an async function along with the <a href="http://devexpress.github.io/testcafe/documentation/test-api/test-code-structure.html#test-controller">test controller</a> object.</li>
<li><code>await</code> is then used to wait for certain <a href="http://devexpress.github.io/testcafe/documentation/test-api/actions/">actions</a> to complete. In this case, we used <code>typeText()</code> and <code>pressKey()</code> to search GitHub.</li>
<li>On the GitHub search results page, we used a <code>Selector()</code> <a href="http://devexpress.github.io/testcafe/documentation/test-api/selecting-page-elements/selectors.html">function</a> to parse the DOM.</li>
<li>Finally, we asserted that the actual results contain the expected results.</li>
</ol>


<blockquote><p><strong>NOTE:</strong> If you&rsquo;re new to <a href="https://github.com/tc39/ecmascript-asyncawait">async/await</a>, check out <a href="https://ponyfoo.com/articles/understanding-javascript-async-await">Understanding JavaScript’s async await</a>.</p></blockquote>

<p>Try this out! Run <code>npm test</code>. If all goes well Chrome should fire up and execute the test. Once done, you should see something like this in your terminal:</p>

<pre><code class="sh">Running tests in:
- Chrome 57.0.2987 / Mac OS X 10.11.6

Getting Started
✓ Find "testcafe-example" repo on GitHub
</code></pre>

<p>Make sense? No? Continue to run the test and review the above steps until it does. Make sure you understand what&rsquo;s happening before moving on.</p>

<h2>Writing Tests</h2>

<p>Add a new file called <em>jobs.js</em> to the &ldquo;tests&rdquo; folder:</p>

<pre><code class="javascript">import { Selector } from 'testcafe';

fixture('Node Jobs')
  .page('http://localhost:3000');

test('All Jobs', async (t) =&gt; {

});
</code></pre>

<p>Then update the <code>test</code> command in <em>package.json</em>:</p>

<pre><code class="json">"test": "node_modules/testcafe/bin/testcafe.js chrome tests/jobs.js --app 'npm start'"
</code></pre>

<p><code>tests/jobs.js</code> ignores the example GitHub test found in <em>index.js</em> so that we can focus just on the tests added to <em>jobs.js</em>. The <code>--app</code> <a href="https://devexpress.github.io/testcafe/documentation/using-testcafe/command-line-interface.html#-a-command---app-command">option</a> is used to launch the Node app so that TestCafe can interact with it.</p>

<p>Try it. You should see the page load in Chrome. With that, let&rsquo;s test each of our app&rsquo;s CRUD functions.</p>

<h3>GET ALL Jobs</h3>

<p>Update <em>jobs.js</em>:</p>

<pre><code class="javascript">import { Selector } from 'testcafe';

fixture('Node Jobs')
  .page('http://localhost:3000');

test('All Jobs', async (t) =&gt; {
  const title = Selector('h1');
  const tableRows = Selector('tbody &gt; tr');
  const addJobButton = Selector('a.btn.btn-primary');
  const firstJob = Selector('tbody &gt; tr').withText('Horse Whisperer');
  // check title, add job button, table rows, and job exists
  await t
    .expect(title.innerText).eql('All Jobs')
    .expect(addJobButton.innerText).eql('Add New Job')
    .expect(tableRows.count).eql(3)
    .expect(firstJob.exists).ok();
});
</code></pre>

<p>What&rsquo;s happening? Review the code above, line by line. It should be fairly straightforward.  Turn to the <a href="https://devexpress.github.io/testcafe/documentation/test-api/selecting-page-elements/">docs</a> for help, adding comments as necessary.</p>

<p>Run:</p>

<pre><code class="sh">Node Jobs
✓ All Jobs


1 passed (0s)
</code></pre>

<p>Before moving on, refactor out the selectors so that they can be re-used by other test cases:</p>

<pre><code class="javascript">import { Selector } from 'testcafe';

// selectors
const title = Selector('h1');
const tableRows = Selector('tbody &gt; tr');
const addJobButton = Selector('a.btn.btn-primary');
const firstJob = Selector('tbody &gt; tr').withText('Horse Whisperer');

fixture('Node Jobs')
  .page('http://localhost:3000');

test('All Jobs', async (t) =&gt; {
  // check title, add job button, table rows, and job exists
  await t
    .expect(title.innerText).eql('All Jobs')
    .expect(addJobButton.innerText).eql('Add New Job')
    .expect(tableRows.count).eql(3)
    .expect(firstJob.exists).ok();
});
</code></pre>

<h3>Add Job</h3>

<p>Start by adding a new <code>test()</code> function to <em>jobs.js</em>:</p>

<pre><code class="javascript">test.only('New Job', async (t) =&gt; {

});
</code></pre>

<blockquote><p><strong>NOTE:</strong> Can you guess what <code>only()</code> does? Try running the tests to see. Please review the <a href="https://devexpress.github.io/testcafe/documentation/test-api/test-code-structure.html#skipping-tests">docs</a> for more info.</p></blockquote>

<p>Think about the steps an end user has to go through to add a job:</p>

<ol>
<li>Click the add job button</li>
<li>Fill out the form</li>
<li>Submit the form</li>
</ol>


<p>Now, try this on your own, step by step, before looking at the solution&hellip;</p>

<pre><code class="javascript">test.only('New Job', async (t) =&gt; {
  // click add job button
  await t
    .click(addJobButton)
    .expect(title.innerText).eql('Add Job');
  // fill out form
  await t
    .typeText('input[name="title"]', 'Python Developer')
    .typeText('textarea[name="description"]', 'Write some Python')
    .typeText('input[name="company"]', 'Real Python')
    .typeText('input[name="email"]', 'michael@realpython.com')
    .click(submitButton)
  // check title, table rows, and new job exists
  await t
    .expect(title.innerText).eql('All Jobs')
    .expect(tableRows.count).eql(4)
    .expect(Selector('tbody &gt; tr').withText('Python Developer').exists).ok();
});
</code></pre>

<p>Make sure to add the selector to the top:</p>

<pre><code class="javascript">const submitButton = Selector('button[type="submit"]');
</code></pre>

<p>Test it out. Then remove the <code>only()</code> and test again:</p>

<pre><code class="sh">Node Jobs
✓ All Jobs
✓ New Job


2 passed (4s)
</code></pre>

<p>What are we missing in this test?</p>

<ol>
<li>What happens if the cancel button is pressed?</li>
<li>What if the end user does not enter data for all the fields?</li>
<li>What if text is entered in the email field but it is not a valid email?</li>
</ol>


<p>Try testing for these on your own.</p>

<h3>Update Job</h3>

<p>Again, start by adding the boilerplate:</p>

<pre><code class="javascript">test('Update Job', async (t) =&gt; {

});
</code></pre>

<p>Then write out the steps the end user has to take before writing any code:</p>

<ol>
<li>Click the update button</li>
<li>Fill out the form</li>
<li>Submit the form</li>
</ol>


<pre><code class="javascript">test('Update Job', async (t) =&gt; {
  // click update button
  await t
    .click(firstJob.find('a.btn.btn-warning'))
    .expect(title.innerText).eql('Update Job');
  // fill out form
  await t
    .typeText('input[name="title"]', 'testing an update', {replace: true})
    .typeText('textarea[name="description"]', 'test', {replace: true})
    .typeText('input[name="company"]', 'test', {replace: true})
    .typeText('input[name="email"]', 't@t.com', {replace: true})
    .click(submitButton)
  // check title, table rows, and updated job exists
  await t
    .expect(title.innerText).eql('All Jobs')
    .expect(tableRows.count).eql(4) // why 4?
    .expect(firstJob.exists).notOk()
    .expect(Selector('tbody &gt; tr').withText('testing an update').exists).ok();
});
</code></pre>

<p>Test:</p>

<pre><code class="sh">Node Jobs
✓ All Jobs
✓ New Job
✓ Update Job


3 passed (8s)
</code></pre>

<p>What else should you test for? Write the test cases on your own.</p>

<p>Also, did you notice the code smell? There&rsquo;s a lot of code duplication happening between those last two test cases. How could this be better handled?</p>

<p>Finally, did you notice that there are still four jobs in the table? Why? Could there be issues with testing the previous two tests together rather than in isolation? Probably not in this case, but if there are, you could always wrap the update in a new <code>fixture()</code>, since this restores the page to its initial state.</p>

<h3>Delete Job</h3>

<p>Run the app again with <code>npm start</code> to review, from the end user&rsquo;s perspective, what happens when you try to delete a job.</p>

<pre><code class="javascript">test('Delete Job', async (t) =&gt; {
  // click delete button
  await t
    .setNativeDialogHandler(() =&gt; true)
    .click(clayDryerJob.find('a.btn.btn-danger'))
  // check title, table rows, and updated job exists
  await t
    .expect(title.innerText).eql('All Jobs')
    .expect(tableRows.count).eql(3) // why 3?
    .expect(clayDryerJob.exists).notOk();
});
</code></pre>

<p>Did you notice the <code>setNativeDialogHandler()</code> function? <a href="https://devexpress.github.io/testcafe/documentation/test-api/handling-native-dialogs.html#dialog-handler">This</a> tells TestCafe how to handle the alert.</p>

<p>What if we click &ldquo;cancel&rdquo; instead of &ldquo;ok&rdquo;?</p>

<pre><code class="javascript">test('Delete Job', async (t) =&gt; {
  // click delete button
  await t
    .setNativeDialogHandler(() =&gt; true) // =&gt; press ok
    .click(clayDryerJob.find('a.btn.btn-danger'))
  // check title, table rows, and updated job exists
  await t
    .expect(title.innerText).eql('All Jobs')
    .expect(tableRows.count).eql(3) // why 3?
    .expect(clayDryerJob.exists).notOk();
    // click delete button
  await t
    .setNativeDialogHandler(() =&gt; false) // =&gt; press cancel
    .click(tableRows.find('a.btn.btn-danger'))
  // check title, table rows, and updated job exists
  await t
    .expect(title.innerText).eql('All Jobs')
    .expect(tableRows.count).eql(3) // why 3?
});
</code></pre>

<p>Run the tests:</p>

<pre><code class="sh">Node Jobs
✓ All Jobs
✓ New Job
✓ Update Job
✓ Delete Job


4 passed (9s)
</code></pre>

<p>Again, handle any edge cases on you own and clean up the code smell.</p>

<h2>Browser Support</h2>

<p>Aside for Chrome, TestCafe <a href="https://devexpress.github.io/testcafe/documentation/using-testcafe/common-concepts/browser-support.html#officially-supported-browsers">supports</a> a number of browsers out-of-the-box. Further, if you don&rsquo;t need to test browser-dependent functionality, then you can use a headless browser.</p>

<p>Start by installing the <a href="https://github.com/ryx/testcafe-browser-provider-nightmare">plugin</a>, which is powered by <a href="https://github.com/segmentio/nightmare">Nightmare</a>:</p>

<pre><code class="sh">$ npm install testcafe-browser-provider-nightmare@0.0.4 --save-dev
</code></pre>

<p>Update the <code>test</code> command in <em>package.json</em>:</p>

<pre><code class="json">"test": "node_modules/testcafe/bin/testcafe.js nightmare tests/jobs.js --app 'npm start'"
</code></pre>

<p>Run the tests, and you should see:</p>

<pre><code class="sh">Running tests in:
- Electron 1.6.2 / Mac OS X 10.11.6

Node Jobs
✓ All Jobs
✓ New Job
✓ Update Job
✓ Delete Job


4 passed (9s)
</code></pre>

<p>There&rsquo;s also a <a href="https://github.com/DevExpress/testcafe-browser-provider-saucelabs">plugin</a> for cross browser support powered by <a href="https://saucelabs.com/">SauceLabs</a>.</p>

<h2>Continuous Integration</h2>

<p>Finally, let&rsquo;s incorporate TestCafe into our Continuous Integration (CI) process with <a href="https://travis-ci.org/">Travis CI</a>.</p>

<blockquote><p><strong>NOTE:</strong> New to Travis? Review the <a href="https://docs.travis-ci.com/user/for-beginners">Travis CI for Complete Beginners</a> guide along with <a href="http://devexpress.github.io/testcafe/documentation/recipes/running-tests-in-firefox-and-chrome-using-travis-ci.html">Running Tests in Firefox and Chrome Using Travis CI</a>.</p></blockquote>

<p>After you enable Travis CI for the repository you are working with, add a <em>.travis.yml</em> file to the project root:</p>

<pre><code>language: node_js
node_js: "7"

dist: trusty
sudo: required

addons:
  apt:
    sources:
     - google-chrome
    packages:
     - google-chrome-stable

before_script:
  - "export DISPLAY=:99.0"
  - "sh -e /etc/init.d/xvfb start"
  - sleep 3
</code></pre>

<p>Here, we added the Node version along with some basic Chrome settings. Also, we have to use <a href="https://docs.travis-ci.com/user/gui-and-headless-browsers/#Using-xvfb-to-Run-Tests-That-Require-a-GUI">xvfb</a> to fake a GUI so that Chrome thinks it&rsquo;s running in a graphical environment.</p>

<hr><br>


<p>That&rsquo;s it. Grab the final code from the <a href="https://github.com/mjhea0/testcafe-example">testcafe-example</a> repo. Comment below if you have questions.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building a RESTful API With Node, Flow, and Jest]]></title>
    <link href="http://mherman.org/blog/2016/12/23/building-a-restful-api-with-node-and-flow/"/>
    <updated>2016-12-23T07:59:54-07:00</updated>
    <id>http://mherman.org/blog/2016/12/23/building-a-restful-api-with-node-and-flow</id>
    <content type="html"><![CDATA[<p>This tutorial details how to develop a RESTful API with <a href="https://nodejs.org/en/">NodeJS</a>, <a href="http://expressjs.com/">ExpressJS</a>, and <a href="https://flowtype.org/">Flow</a> using test-driven development (TDD).</p>

<p>We&rsquo;ll be going full-Facebook with this application (FaceStack), utilizing:</p>

<ul>
<li><a href="https://flowtype.org/">Flow</a> for type checking</li>
<li><a href="http://babeljs.io/">Babel</a> for transpilation</li>
<li><a href="https://facebook.github.io/jest/">Jest</a> for our testing framework</li>
<li>(Optionally) <a href="https://yarnpkg.com/">Yarn</a> to replace <a href="https://www.npmjs.com/">NPM</a></li>
</ul>


<h2>Contents</h2>

<ol>
<li>Project Setup</li>
<li>Server Setup</li>
<li>Test Setup</li>
<li>First Endpoint</li>
<li>Rounding out CRUD</li>
<li>Conclusion</li>
</ol>


<h2>Project Setup</h2>

<p>Create a new directory to hold the project:</p>

<pre><code class="sh">$ mkdir flow-node-api
$ cd flow-node-api
</code></pre>

<h3>Transpilation</h3>

<p>To start, let&rsquo;s get Babel transpilation up and running. We&rsquo;ll use <a href="http://gulpjs.com/">Gulp</a> to automate the build process.</p>

<blockquote><p><strong>NOTE:</strong> W&rsquo;ll use <a href="https://yarnpkg.com/">yarn</a> here to download and manage dependencies, but you can use <code>npm</code> just as easily if you wish. Anytime you see a <code>yarn add</code> or <code>yarn remove</code> just substitute in a <code>npm install</code> or <code>npm rm</code>. The only difference is that yarn does the <code>--save</code> part for you and with <code>npm</code> you must be explicit.</p></blockquote>

<p>Go ahead and add <code>gulp</code>, <code>gulp-babel</code>, and <code>gulp-sourcemaps</code> to your project, and create a <em>gulpfile.js</em> to start writing our Gulp tasks in:</p>

<pre><code class="sh">$ yarn init -y
$ yarn add gulp@3.9.1 gulp-babel@6.1.2 gulp-sourcemaps@1.9.1
$ touch gulpfile.js
</code></pre>

<p>Also, install Gulp globally (if necessary), so you can run Gulp tasks from the command line:</p>

<pre><code class="sh">$ yarn global add gulp-cli@1.2.2
</code></pre>

<p>We&rsquo;re going to write all of our source code in the &ldquo;src&rdquo; directory, so the first  Gulp task will need to:</p>

<ol>
<li>Grab all of the JavaScript files inside of &ldquo;src&rdquo;</li>
<li>Pipe the files through Babel</li>
<li>Deliver them to the &ldquo;build&rdquo; directory</li>
</ol>


<pre><code class="javascript">const gulp = require('gulp');
const babel = require('gulp-babel');
const sourcemaps = require('gulp-sourcemaps');

gulp.task('scripts', () =&gt; {
  return gulp.src('src/**/*.js')
  .pipe(sourcemaps.init())
  .pipe(babel())
  .pipe(sourcemaps.write('.'))
  .pipe(gulp.dest('build'));
});
</code></pre>

<p>Pretty straightforward. Time to test!</p>

<p>Add a &ldquo;src&rdquo; directory, and then create a file inside of it called <em>index.js</em>:</p>

<pre><code class="sh">$ mkdir src &amp;&amp; touch src/index.js
</code></pre>

<p>Put some kind of JavaScript statement inside of your newly created file, like:</p>

<pre><code class="javascript">// src/index.js
console.log('Hello World!');
</code></pre>

<p>Run the Gulp task, and then run the transpiled version of <em>index.js</em>:</p>

<pre><code class="sh">$ gulp scripts
$ node build/index.js
Hello World!
</code></pre>

<p>Nice! However, do you really want to manually type <code>gulp scripts</code> in to build the project <em>every</em> time changes are made? Of course not. So, let&rsquo;s set up a <code>watch</code> and a <code>default</code> task with Gulp to make this easier.</p>

<p>Add the following to <code>gulpfile.js</code>:</p>

<pre><code class="javascript">gulp.task('watch', ['scripts'], () =&gt; {
  gulp.watch('src/**/*.js', ['scripts']);
});

gulp.task('default', ['watch']);
</code></pre>

<p>Now you can just run <code>gulp</code> from the command line, and it will listen for changes to our JavaScript files inside of &ldquo;src&rdquo; and re-run the <code>scripts</code> task whenever it detects changes.</p>

<h3>Flow</h3>

<p>Moving on, to use <a href="https://flowtype.org/">Flow</a>, we&rsquo;ll use the <code>gulp-flowtype</code> plugin to interface with Flow. Download the dependency and head back over to <code>gulpfile.js</code>.</p>

<pre><code class="sh">$ yarn add --dev gulp-flowtype@1.0.0
</code></pre>

<pre><code class="javascript">// ...
const flow = require('gulp-flowtype');
// ...

gulp.task('flow', () =&gt; {
  return gulp.src('src/**/*.js')
  .pipe(flow({ killFlow: false }));
});
// ...

// update the watch task as well
gulp.task('watch', ['flow', 'scripts'], () =&gt; {
  gulp.watch('src/**/*.js', ['flow', 'scripts']);
});
</code></pre>

<p>This is all well and good, but we&rsquo;re going to configure a few more parts before we move forward. We need to tell Babel to strip out all of our Flow <a href="https://flowtype.org/docs/type-annotations.html">type annotations</a>. While we&rsquo;re doing that, we might as well install the other Babel dependencies:</p>

<pre><code class="sh">$ yarn add babel-plugin-transform-flow-strip-types@6.21.0
$ yarn add babel-polyfill@6.20.0 babel-preset-latest@6.16.0
</code></pre>

<p>With those installed create a <em>.babelrc</em> file in the root of the project, and add these settings:</p>

<pre><code class="json">{
  "presets": ["latest"],
  "plugins": ["transform-flow-strip-types"]
}
</code></pre>

<p>Finally, we need a <em>.flowconfig</em> to tell Flow that this is a project with Flow annotated code. If you have the Flow CLI installed, you can do this with <code>flow init</code>. If you don&rsquo;t, just create a file called <em>.flowconfig</em>  file and paste this in:</p>

<pre><code>[ignore]

[include]

[libs]

[options]
</code></pre>

<p>Whew. Now that we&rsquo;ve done all that configuring, let&rsquo;s make sure it&rsquo;s all working by testing out some Flow type annotations. If you&rsquo;re familiar with <a href="http://mherman.org/blog/2016/11/05/developing-a-restful-api-with-node-and-typescript/">TypeScript</a>, this syntax will look very familiar. There are some notable differences, but in general TypeScript and Flow look pretty similar. Let&rsquo;s start with a simple function that adds two numbers together.</p>

<p>Run the default gulp task:</p>

<pre><code class="sh">$ gulp
</code></pre>

<p>Replace the contents of <em>src/index.js</em> with the following:</p>

<pre><code class="javascript">// @flow

function testFunc(item) {
  return 10 * item;
}

console.log(testFunc(2));
console.log(testFunc('banana'));
</code></pre>

<p>Since Gulp is watching for changes, you should automatically see the output from Flow as soon as you save the file:</p>

<pre><code class="sh">src/index.js:4
  4:   return 10 * item;
                   ^^^^ string. This type is incompatible with
  4:   return 10 * item;
              ^^^^^^^^^ number
</code></pre>

<p>Excellent! Flow is doing its job. Here, it&rsquo;s telling us that when we try to call <code>testFunc('banana')</code> we&rsquo;re going to run into issues because <code>testFunc</code> is clearly expecting its argument to be a number, not a string. Notice the <code>// @flow</code> comment that&rsquo;s now at the top of the file. This tells Flow that this file should be <a href="https://en.wikipedia.org/wiki/Type_system#Type_checking">typechecked</a>. If you don&rsquo;t put this comment at the top of the file you&rsquo;re working on, Flow will ignore it. Keep this in mind as you develop your application.</p>

<p>If you read the post on TypeScript (<a href="http://mherman.org/blog/2016/11/05/developing-a-restful-api-with-node-and-typescript">Developing a RESTful API With Node and TypeScript</a>), you may already be wondering how we can use types with third-party libraries. Well, with Flow there&rsquo;s a command line tool called <a href="https://github.com/flowtype/flow-typed">flow-typed</a> that is used to manage libdefs (library definitions) for Flow.</p>

<p>First, install <code>flow-typed</code> globally:</p>

<pre><code class="sh">$ yarn global add flow-typed@2.0.0
</code></pre>

<p>The nice thing about <code>flow-typed</code> is that we don&rsquo;t really have to manage it too much. It reads <code>package.json</code> and automatically downloads the libdefs for our dependencies and stores them in &ldquo;flow-typed&rdquo;.</p>

<p>To install the libdefs for the packages we&rsquo;re using so far just run:</p>

<pre><code class="sh">$ flow-typed install --flowVersion=0.36.0
</code></pre>

<p>For packages that have no official libdef in the flow-typed repository, a stub is generated. Unfortunately, if you want to omit the <code>--flowVersion=0.36.0</code> flag, you&rsquo;ll need to install <code>flow-bin</code> and have it listed as a dependency in <em>package.json</em>.</p>

<p>Before moving forward, we need to make one more change to our Gulp task for Flow. Now that we&rsquo;ve got <code>flow-typed</code>, tell Flow where we&rsquo;re keeping these definitions:</p>

<pre><code class="javascript">gulp.task('flow', () =&gt; {
  return gulp.src('src/**/*.js')
  .pipe(flow({
    killFlow: false,
    declarations: './flow-typed'
  }));
});
</code></pre>

<p>Great! We&rsquo;ve got Flow type checking our code, and Babel is stripping out our type annotations and transpiling.</p>

<p>Let&rsquo;s construct the basics of the server.</p>

<h2>Server Setup</h2>

<p>We&rsquo;re going to use <em>src/index.js</em> as the entry point for our Express API along with the <a href="https://github.com/visionmedia/debug">debug</a> module to set up simple logging. Install it with <code>yarn</code> (<code>yarn add debug@2.4.5</code>) or <code>npm</code> (<code>npm install debug@2.4.5 --save</code>), and then wipe everything out of <em>index.js</em> and replace it with the following:</p>

<pre><code class="javascript">// @flow

'use strict'

import * as http from 'http';
import debug from 'debug';
import Api from './Api';

// ErrnoError interface for use in onError
declare interface ErrnoError extends Error {
  errno?: number;
  code?: string;
  path?: string;
  syscall?: string;
}

const logger = debug('flow-api:startup');
const app: Api = new Api();
const DEFAULT_PORT: number = 3000;
const port: string | number = normalizePort(process.env.PORT);
const server: http.Server = http.createServer(app.express);

server.listen(port);
server.on('error', onError);
server.on('listening', onListening);

function normalizePort(val: any): number | string {
  let port: number = (typeof val === 'string') ? parseInt(val, 10) : val;

  if (port &amp;&amp; isNaN(port)) return port;
  else if (port &gt;= 0) return port;
  else return DEFAULT_PORT;
}

function onError(error: ErrnoError): void {
  if (error.syscall !== 'listen') throw error;
  let bind: string = (typeof port === 'string') ? `Pipe ${port}` : `Port ${port.toString()}`;

  switch (error.code) {
    case 'EACCES':
      console.error(`${bind} requires elevated privileges`);
      process.exit(1);
      break;
    case 'EADDRINUSE':
      console.error(`${bind} is already in use`);
      process.exit(1);
      break;
    default:
      throw error;
  }
}

function onListening(): void {
  let addr: string = server.address();
  let bind: string = (typeof addr === 'string') ? `pipe ${addr}` : `port ${addr.port}`;
  logger(`Listening on ${bind}`);
}
</code></pre>

<p>Alright. This looks like a lot of code, but it&rsquo;s mostly boilerplate with some fancy type annotations added. Let&rsquo;s break it down real quick though anyways:</p>

<ul>
<li>At the top we&rsquo;ve got our Flow comment, imports, and our first bit of strictly Flow-enabled code - the <code>ErrnoError</code> interface declaration. This error type is used by Express. When using the <code>flow check</code> command from the official command line tool, Flow will not flag this as an error. For whatever reason, <code>gulp-flowtype</code> does. If you get a strange type check error, it may be worth it to install the Flow CLI and double check using <code>flow check</code>.</li>
<li>After the <code>ErrnoError</code> definition, we set up some data and instantiate the server by attaching our future Express app with <code>http.createServer</code>.</li>
<li><code>normalizePort</code> looks for the <code>$PORT</code> environment variable and sets the app&rsquo;s port to its value. If it doesn&rsquo;t exist, it sets the port to the default value - <code>3000</code>.</li>
<li><code>onError</code> is just our basic error handler for the HTTP server.</li>
<li><code>onListening</code> simply lets us know that our application has actually started and is listening for requests.</li>
</ul>


<p>Run <code>gulp</code>. Right now, you should see Flow complaining about trying to import the API:</p>

<pre><code class="sh">src/index.js:7
  7: import Api from './Api';
                     ^^^^^^^ ./Api. Required module not found
</code></pre>

<p>This makes sense because we don&rsquo;t even have a file called <em>Api.js</em>, so let&rsquo;s create it and set up the basic structure for the API. In this file, the third-party libraries we&rsquo;ll be using are:</p>

<ul>
<li><a href="http://expressjs.com/">Express</a> - web framework</li>
<li><a href="https://github.com/expressjs/body-parser">body-parser</a> - JSON body parser for HTTP requests</li>
<li><a href="https://github.com/expressjs/morgan">morgan</a> - request logging</li>
</ul>


<pre><code class="sh">$ yarn add express@4.14.0 body-parser@1.15.2 morgan@1.7.0
$ flow-typed install --flowVersion=0.36.0
$ touch src/Api.js
</code></pre>

<p>With the dependencies and libdefs acquired, we&rsquo;re ready to build out the <code>Api.js</code> file:</p>

<pre><code class="javascript">// @flow

import express from 'express';
import morgan from 'morgan';
import bodyParser from 'body-parser';

export default class Api {
  // annotate with the express $Application type
  express: express$Application;

  // create the express instance, attach app-level middleware, attach routers
  constructor() {
    this.express = express();
    this.middleware();
    this.routes();
  }

  // register middlewares
  middleware(): void {
    this.express.use(morgan('dev'));
    this.express.use(bodyParser.json());
    this.express.use(bodyParser.urlencoded({extended: false}));
  }

  // connect resource routers
  routes(): void {
    this.express.use((req: $Request, res: $Response) =&gt; {
      res.json({ message: 'Hello Flow!' });
    });
  }
}
</code></pre>

<p>Most of this file ends up just loading and initializing the libraries that we&rsquo;re using. There are a few things to note though:</p>

<ul>
<li>First, we create a field reference for the <code>Api.express</code> property, and tell Flow that it will be an object of type <code>express$Application</code> from Express.</li>
<li>The constructor initializes an instance of Express, and attaches it to the instance of <code>Api</code>. Then it calls the other two methods, <code>Api.middleware</code> and <code>Api.routes</code>.</li>
<li><code>Api.middleware</code> - Initializes and attaches our middleware modules to the app.</li>
<li><code>Api.routes</code> - Right now, it attaches a single route handler that returns some JSON. However, notice the Flow annotations on the parameters of the anonymous function. These correspond to the base arguments for an Express route handler: <code>$Request</code> and <code>$Response</code>. These refer to Express' extended versions of Node&rsquo;s <code>IncomingMessage</code> and <code>ServerResponse</code> objects, respectively.</li>
</ul>


<p>At this point, you may start to see a Flow error in your terminal that looks something like this:</p>

<pre><code class="sh">src/index.js:12
 12: const server: Server = http.createServer(app.express);
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ call of method `createServer`
835:     requestListener?: (request: IncomingMessage, response: ServerResponse) =&gt; void
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ function type. Callable signature not found in. See lib: /private/tmp/flow/flowlib_120ceaae/node.js:835
 12: const server: Server = http.createServer(app.express);
                                              ^^^^^^^^^^^ express$Application
</code></pre>

<p>It would appear that Flow doesn&rsquo;t get the memo that when <code>app.express</code> is called, it does return a request handler. This seems to be an issue with the libdef for Express, because it declares that the <code>express$Application</code> constructor has a return type of <code>void</code>.</p>

<blockquote><p><strong>NOTE:</strong> After unsuccessfully messing with the libdef for a while, I decided I knew that it worked better than Flow, and moved on. If the terminal output bugs you, go ahead and add this comment to the line above where <code>http.createServer</code> is called:</p>

<pre><code class="javascript">// $FlowFixMe: express libdef issue
</code></pre></blockquote>

<p>Let&rsquo;s go ahead and fire up the app and make sure everything is working as intended thus far. To run the app from the command line, you can run <code>node build/index.js</code>. However, we really should have a start script so we can just type <code>npm start</code> to run the server. Open up <code>package.json</code> and add the following:</p>

<pre><code class="json">"scripts": {
  "start": "DEBUG=\"flow-api:*\" node build/index.js"
}
</code></pre>

<p>The first part of the command just sets the <code>DEBUG</code> environment variable to <code>flow-api:*</code>, so that the <code>debug</code> module writes our logs to stdout. Now you can run <code>npm start</code>, and you should see:</p>

<pre><code class="sh">&gt; DEBUG="flow-api:*" node build/index.js

  flow-api:startup Listening on port 3000 +0ms
</code></pre>

<p>Awesome! The server is listening. Now, if we hit any endpoint, it should send back our <code>{ message: "Hello Flow!" }</code> payload. You can use <a href="https://httpie.org/">httpi</a> for this kind of thing. If you&rsquo;re on a Mac you can install it with Homebrew: <code>brew install httpie</code>. Then within a new terminal window run:</p>

<pre><code class="sh">$ http localhost:3000/
</code></pre>

<p>And you should see:</p>

<pre><code class="sh">→ HTTP/1.1 200 OK
Connection: keep-alive
Content-Length: 25
Content-Type: application/json; charset=utf-8

{
    "message": "Hello Flow!"
}
</code></pre>

<p>And we&rsquo;re up and running! At this point, we&rsquo;ve got the base Express application up and running. Now we just need to build out a router that does something useful!</p>

<h2>Test Setup</h2>

<p>Not so fast! Rather than jumping straight into the RESTful router, we&rsquo;re going to set up our testing environment so that as we create endpoints and handlers we can test that they work as we expect. Since we&rsquo;re using the FaceStack, we&rsquo;ll use <a href="https://facebook.github.io/jest/">Jest</a> as well as <a href="https://github.com/WhoopInc/supertest-as-promised">supertest-as-promised</a> to interface with our Express API.</p>

<p>Install the packages:</p>

<pre><code class="sh">$ yarn add --dev jest@18.0.0 supertest@2.0.1 supertest-as-promised@4.0.2
</code></pre>

<p>Open up <em>package.json</em> again and add a few lines to configure Jest:</p>

<pre><code class="json">"jest": {
  "transform": {".*": "&lt;rootDir&gt;/node_modules/babel-jest"}
}
</code></pre>

<p>This just tells Jest to use Babel and our Babel configuration to interpret our test files and the files they test. To run our tests from the command line, we just need to add a test script to <code>package.json</code>:</p>

<pre><code class="json">"scripts": {
  "start": "DEBUG=\"flow-api:*\" node build/index.js",
  "test": "jest"
}
</code></pre>

<p>Right now, if you run it, Jest is just going to tell you it couldn&rsquo;t find any tests So, let&rsquo;s fix that. Create a directory called <em>__tests__</em> in the project root, and inside of it add a file to hold our first test:</p>

<pre><code class="sh">$ mkdir __tests__ &amp;&amp; touch __tests__/first.test.js
</code></pre>

<pre><code class="javascript">import request from 'supertest-as-promised';
import Api from '../src/Api';

const app = new Api().express;

describe('Flow API', () =&gt; {
  it('hello test', () =&gt; {
    return request(app).get('/')
    .expect(200)
    .then((res) =&gt; {
      expect(typeof res.body.message).toBe('string');
      expect(res.body.message).toBe('Hello Flow!');
    });
  });
});
</code></pre>

<p>This is a pretty simple test, but it should at least demonstrate the basic structure of what we&rsquo;re doing here. If you&rsquo;re saying to yourself, &ldquo;Hey, this looks a lot like Jasmine!&rdquo;,  you&rsquo;re right it does, because Jest is built on top of Jasmine. Here&rsquo;s a quick breakdown of this first test file:</p>

<ul>
<li>We import the <code>Api</code> class and <code>supertest-as-promised</code> to create the interface to the API. This way we don&rsquo;t have to manage starting and stopping the server or actually sending requests over a network connection.</li>
<li>We assert that we&rsquo;re expecting a 200 status code.</li>
<li>When the response comes back, we assert that the payload should have a property called <code>message</code>, who&rsquo;s value is a string, and that string should equal: &ldquo;Hello Flow!&rdquo;</li>
</ul>


<p>Go ahead and run the tests, <code>npm test</code>, and you should see this output:</p>

<pre><code class="sh">&gt; jest

 PASS  __tests__/first.test.js
  Flow API
    ✓ hello test (42ms)

Test Suites: 1 passed, 1 total
Tests:       1 passed, 1 total
Snapshots:   0 total
Time:        2.03s
Ran all test suites.
GET / 200 4.059 ms - 25
</code></pre>

<p>With the test environment set up, let&rsquo;s build out our first endpoint!</p>

<h2>First Endpoint</h2>

<p>Now, we&rsquo;re going to implement CRUD with a single resource - produce. You can use any resource you want or grab the fake data we used <a href="https://raw.githubusercontent.com/mjhea0/flow-node-api/master/data/produce.json">here</a>. In case you&rsquo;re blanking on what CRUD means, we&rsquo;re going to implement 4 actions that the API will support for the produce resource:</p>

<ol>
<li>Create a produce item.</li>
<li>Read produce item(s).</li>
<li>Update a produce item.</li>
<li>Delete a produce item.</li>
</ol>


<p>We&rsquo;ll start by implementing the <code>GET</code> handler that returns all the produce in our inventory, with the following shape:</p>

<pre><code class="javascript">{
  id: integer,
  name: string,
  quantity: integer,
  price: integer
}
</code></pre>

<blockquote><p><strong>NOTE:</strong> The <code>id</code> property will not be supplied by the user, but assigned when an item is created by the API.</p></blockquote>

<p>Let&rsquo;s start by first writing some tests that we can test our implementation against as we write it. Rename <em>first.test.js</em> to <em>ProduceRouter.test.js</em>, and replace the current <code>describe</code> block with these tests for the <code>GET</code> all endpoint:</p>

<pre><code class="javascript">describe('Flow API', () =&gt; {

  describe('GET /api/v1/produce - get all produce', () =&gt; {
    // properties expected on an obj in the response
    let expectedProps = ['id', 'name', 'quantity', 'price'];
    it('should return JSON array', () =&gt; {
      return request(app).get('/api/v1/produce')
      .expect(200)
      .then(res =&gt; {
        // check that it sends back an array
        expect(res.body).toBeInstanceOf(Array);
      });
    });
    it('should return objs w/ correct props', () =&gt; {
      return request(app).get('/api/v1/produce')
      .expect(200)
      .then(res =&gt; {
        // check for the expected properties
        let sampleKeys = Object.keys(res.body[0]);
        expectedProps.forEach((key) =&gt; {
          expect(sampleKeys.includes(key)).toBe(true);
        });
      });
    });
    it('shouldn\'t return objs w/ extra props', () =&gt; {
      return request(app).get('/api/v1/produce')
      .expect(200)
      .then(res =&gt; {
        // check for only expected properties
        let extraProps = Object.keys(res.body[0]).filter((key) =&gt; {
          return !expectedProps.includes(key);
        });
        expect(extraProps.length).toBe(0);
      });
    });
  });

});
</code></pre>

<p>Inside of the outer <code>describe</code>, we&rsquo;ve added a nested block to indicate that all of the tests inside of it are related and, thus, testing the same feature. These three tests are pretty basic and check that:</p>

<ul>
<li>We get an array back.</li>
<li>The objects in the array have the required properties.</li>
<li>The objects in the array do not have extra properties.</li>
</ul>


<p>Run the tests from the terminal with <code>npm test</code> and you should see them all fail:</p>

<pre><code class="sh">Flow API
  GET /api/v1/produce - get all produce
    ✕ should return JSON array (42ms)
    ✕ should return objs w/ correct props (9ms)
    ✕ shouldn't return objs w/ extra props (4ms)

Test Suites: 1 failed, 1 total
Tests:       3 failed, 3 total
Snapshots:   0 total
Time:        1.835s, estimated 2s
Ran all test suites.
</code></pre>

<p>Now, let&rsquo;s get rid of all those errors and failed tests, and implement the endpoint.</p>

<p>Create a new directory inside of &ldquo;src&rdquo; called &ldquo;routers&rdquo; and add a file called <em>ProduceRouter.js</em>. This is where we&rsquo;ll implement the handler functions for all of the endpoints designated for the produce resource.</p>

<blockquote><p><strong>NOTE:</strong> Remember - For Flow to type check the file, you have to add the <code>@flow</code> comment at the very top of the file!</p></blockquote>

<pre><code class="javascript">// @ flow

import inventory from '../../data/produce';
import { Router }  from 'express';

export default class ProduceRouter {
  // these fields must be type annotated, or Flow will complain!
  router: Router;
  path: string;

  // take the mount path as the constructor argument
  constructor(path = '/api/v1/produce') {
    // instantiate the express.Router
    this.router = Router();
    this.path = path;
    // glue it all together
    this.init();
  }

  /**
   * Return all items in the inventory
   */
  getAll(req: $Request, res: $Response): void {
    res.status(200).json(inventory);
  }

  /**
   * Attach route handlers to their endpoints.
   */
  init(): void {
    this.router.get('/', this.getAll);
  }
}
</code></pre>

<p>The <code>ProduceRouter</code> holds fields for an Express <code>Router</code> instance, and a <code>path</code> property that holds its mount point to the application. The constructor takes this mount point as its only argument and then attaches the endpoint handlers to their endpoints.</p>

<blockquote><p><strong>NOTE:</strong>  The field type annotations for <code>router</code> and <code>path</code> are not strictly required (as far as I can tell). You can get rid of them, and Flow will not complain. But you can&rsquo;t have field declarations without types. It doesn&rsquo;t like that at all. I tend to use them because they&rsquo;re a useful quick reference to the properties on an object.</p></blockquote>

<p>The <code>getAll</code> function has the basic function signature of an Express route handler, and it simply responds to requests with the full inventory list. Notice that the return type is <code>void</code>. This is because of the middleware architecture that Express is built on. Each middleware function is run in sequence, rather than returning a value from the handler.</p>

<p>Finally, in <code>init</code> we will take each of our route handlers, and attach it to a mount path on the router. Each endpoint will be prefixed with the overall <code>Router</code> mount path that is passed to the <code>ProduceRouter</code> constructor. Right now, our <code>ProduceRouter</code> is responding to <code>GET</code> requests at the <code>/api/v1/produce</code> endpoint.</p>

<p>We&rsquo;re done in this file for now, but we&rsquo;ll have to hop back over to <code>Api.js</code> in order to finish linking these things up.</p>

<p>Add an import statement for <code>ProduceRouter</code> at the top:</p>

<pre><code class="javascript">import ProduceRouter from './routers/ProduceRouter';
</code></pre>

<p>And then replace the <code>routes</code> function with:</p>

<pre><code class="javascript">// connect resource routers
routes(): void {
  // create an instance of ProduceRouter
  const produceRouter = new ProduceRouter();

  // attach it to our express app
  this.express.use(produceRouter.path, produceRouter.router);
}
</code></pre>

<p>Here, we simply create an instance of the <code>ProduceRouter</code> class, and attach it to the Express application path specified by its <code>path</code> property. Now cross your fingers and run <code>npm test</code>:</p>

<pre><code class="sh">PASS  __tests__/ProduceRouter.test.js
 Flow API
   GET /api/v1/produce - get all produce
     ✓ should return JSON array (43ms)
     ✓ should return objs w/ correct props (10ms)
     ✓ shouldn't return objs w/ extra props (4ms)

Test Suites: 1 passed, 1 total
Tests:       3 passed, 3 total
Snapshots:   0 total
Time:        2.052s
Ran all test suites.
</code></pre>

<p>Victory! Go ahead and pat yourself on the back, maybe stretch the legs or get a snack. We&rsquo;ll work out the rest of the endpoints in the next section.</p>

<h2>Rounding out CRUD</h2>

<p>We&rsquo;ve already got one aspect of the &ldquo;Read&rdquo; part of CRUD complete. Let&rsquo;s knock the other one out now. Rather than only being able to get the full list of items, we need to enable requesting items by their <code>id</code>s. First, we need some tests. Start by making sure that this <code>getById</code> handler will:</p>

<ul>
<li>Return an object of the correct type.</li>
<li>Return the record that lines up with the <code>id</code> sent with the request.</li>
<li>Reject out-of-bounds <code>id</code>s.</li>
</ul>


<pre><code class="javascript">describe('GET /api/v1/produce/:id - get produce item by id', () =&gt; {
  it('should return an obj of type Produce', () =&gt; {
    return request(app).get('/api/v1/produce/1')
    .expect(200)
    .then((res) =&gt; {
      const reqKeys = ['id', 'name', 'price', 'quantity'];
      const {item} = res.body;
      // check it has correct keys
      reqKeys.forEach((key) =&gt; {
        expect(Object.keys(item)).toContain(key);
      });
      // check type of each field
      expect(typeof item.id).toBe('number');
      expect(typeof item.name).toBe('string');
      expect(typeof item.quantity).toBe('number');
      expect(typeof item.price).toBe('number');
    });
  });
  it('should return a Produce w/ requested id', () =&gt; {
    return request(app).get('/api/v1/produce/1')
    .expect(200)
    .then((res) =&gt; {
      expect(res.body.item).toEqual({
        id: 1,
        name: 'banana',
        quantity: 15,
        price: 1
      });
    });
  });
  it('should 400 on a request for a nonexistant id', () =&gt; {
    return Promise.all([
      request(app).get('/api/v1/produce/-32')
      .expect(400)
      .then((res) =&gt; {
        expect(res.body.message).toBe('No item found with id: -32');
      }),
      request(app).get('/api/v1/produce/99999')
      .expect(400)
      .then((res) =&gt; {
        expect(res.body.message).toBe('No item found with id: 99999');
      })
    ]);
  });
});
</code></pre>

<p>Run those new tests and make sure they fail like they should:</p>

<pre><code class="sh">Flow API
  GET /api/v1/produce - get all produce
    ✓ should return JSON array (38ms)
    ✓ should return objs w/ correct props (8ms)
    ✓ shouldn't return objs w/ extra props (5ms)
  GET /api/v1/produce/:id - get produce item by id
    ✕ should return an obj of type Produce (6ms)
    ✕ should return a Produce w/ requested id (2ms)
    ✕ should 400 on a request for a nonexistant id (9ms)

Test Suites: 1 failed, 1 total
Tests:       3 failed, 3 passed, 6 total
Snapshots:   0 total
Time:        1.857s, estimated 2s
Ran all test suites.
</code></pre>

<p>Good. Now we can work on making them pass. This one isn&rsquo;t so bad. We just need to parse the ID number from the request params, and find an item in the <code>inventory</code> array with the same ID.</p>

<pre><code class="javascript">/**
 * Return an item from the inventory by ID.
 */
getById(req: $Request, res: $Response): void {
  const id = parseInt(req.params.id, 10);
  const record = inventory.find(item =&gt; item.id === id);
  if (record) {
    res.status(200).json({
      message: 'Success!',
      item: record
    });
  } else {
    res.status(400).json({
      status: res.status,
      message: `No item found with id: ${id}`
    });
  }
}
</code></pre>

<p>Not particularly exciting, but it works for now! Just make sure to add the handler as well:</p>

<pre><code class="javascript">this.router.get('/:id', this.getById);
</code></pre>

<p>That does it for the &ldquo;R&rdquo; in CRUD.</p>

<h3>POST - Create a New Item</h3>

<p>Let&rsquo;s knock out the &ldquo;C&rdquo; now. We&rsquo;re going to allow <code>POST</code>s to the endpoint <code>/api/v1/produce</code> to be used for creating new items for the inventory. In addition, we&rsquo;ll require that the <code>quantity</code>, <code>price</code>, and <code>name</code> properties are passed.</p>

<p>Tests:</p>

<pre><code class="javascript">describe('POST /api/v1/produce - create new item', () =&gt; {
  let peach = {
    name: 'peach',
    quantity: 10,
    price: 6
  };
  it('should accept and add a valid new item', () =&gt; {
    return request(app).post('/api/v1/produce')
    .send(peach)
    .then((res) =&gt; {
      expect(res.body.status).toBe(200);
      expect(res.body.message).toBe('Success!');
      return request(app).get('/api/v1/produce');
    })
    .then((res) =&gt; {
      let returnedPeach = res.body.find(item =&gt; item.name === 'peach');
      expect(res.status).toBe(200);
      expect(returnedPeach.quantity).toBe(10);
      expect(returnedPeach.price).toBe(6);
    });
  });
  it('should reject post w/o name, price, or quantity', () =&gt; {
    let badItems = [
      {
        name: peach.name,
        quantity: peach.quantity
      },
      {
        quantity: peach.quantity,
        price: peach.price
      },
      {
        name: peach.name,
        price: peach.price
      }
    ];
    return Promise.all(badItems.map(badItem =&gt; {
      return request(app).post('/api/v1/produce')
      .send(badItem)
      .then((res) =&gt; {
        expect(res.body.status).toBe(400);
        expect(res.body.message.startsWith('Bad Request')).toBe(true);
      });
    }));
  });
});
</code></pre>

<p>Verify that the tests fail with <code>npm test</code>, then add another method to <code>ProduceRouter</code> called <code>postOne</code>.</p>

<blockquote><p><strong>NOTE:</strong> I ended up also writing functions to parse the payload from the request, as well as one to re-write our JSON &ldquo;database&rdquo; file. You can either include those as helper methods somewhere in the same file as <code>ProduceRouter</code>, or define them in a different file and import it. If you decide to import it, make sure that you type annotate the function so that Flow can work with its types. I chose to define them in different files and export them from there.</p></blockquote>

<pre><code class="javascript">/**
 * Add a new item to the inventory.
 */
postOne(req: $Request, res: $Response): void {
  const received: Produce | boolean = parseProduce(req.body);
  const newProduce = (received) ? req.body : null;
  if (received) {
    newProduce.id = genId(received, inventory);
    inventory.push(newProduce);
    res.status(200).json({
      status: 200,
      message: 'Success!',
      item: newProduce
    });
    // write updated inventory to the file
    saveInventory(inventory)
    .then((writePath) =&gt; {
      logger(`Inventory updated. Written to:\n\t${path.relative(path.join(__dirname, '..', '..'), writePath)}`);
    })
    .catch((err) =&gt; {
      logger('Error writing to inventory file.');
      logger(err.stack);
    });
  } else {
    res.status(400).json({
      status: 400,
      message: 'Bad Request. Make sure that you submit an item with a name, quantity, and price.'
    });
    logger('Malformed POST to /produce.');
  }
}
</code></pre>

<p>Create a new folder within &ldquo;src&rdquo; called &ldquo;util&rdquo;. Then add a <em>parsers.js</em> file:</p>

<pre><code class="javascript">export function parseProduce(input: any): boolean {
  const requirements = [
    { key: 'name', type: 'string' },
    { key: 'quantity', type: 'number' },
    { key: 'price', type: 'number' }
  ];
  return requirements.every((req) =&gt; {
    return input.hasOwnProperty(req.key) &amp;&amp; typeof input[req.key] === req.type;
  });
}
</code></pre>

<p>&hellip;and <em>save.js</em>:</p>

<pre><code class="javascript">// @flow

import path from 'path';
import fs from 'fs';

// use a Flow type import to get our Produce type
import type {Produce} from './types';

export default function saveInventory(inventory: Array&lt;Produce&gt;): Promise&lt;string&gt; {
  let outpath = path.join(__dirname, '..', '..', 'data', 'produce.json');

  return new Promise((resolve, reject) =&gt; {
    // lets not write to the file if we're running tests
    if (process.env.NODE_ENV !== 'test') {
      fs.writeFile(outpath, JSON.stringify(inventory, null, '\t'), (err) =&gt; {
        (err) ? reject(err) : resolve(outpath);
      });
    }
  });
}

export function genId(prod: Produce, inv: Array&lt;Produce&gt;): number {
  let maxId: number | typeof undefined = inv[0].id;
  inv.slice(1).forEach((item) =&gt; {
    if (item.id &amp;&amp; item.id &gt; maxId) maxId = item.id;
  });
  return maxId + 1;
}
</code></pre>

<p>We don&rsquo;t have tests written currently for these, but they&rsquo;re pretty simple functions. Most importantly, now we have a couple utility functions that we can reuse. We&rsquo;ll definitely need to reuse <code>saveInventory</code> whenever we need to persist changes to the JSON file holding the inventory.</p>

<p>Add the imports to <em>ProduceRouter.js</em>:</p>

<pre><code class="javascript">import saveInventory, {genId} from '../util/save';
import { parseProduce } from '../util/parsers';
</code></pre>

<p>Then update the <code>init()</code>:</p>

<pre><code class="javascript">/**
 * Attach route handlers to their endpoints.
 */
init(): void {
  this.router.get('/', this.getAll);
  this.router.get('/:id', this.getById);
  this.router.post('/', this.postOne);
}
</code></pre>

<p>With this code filled in, run <code>npm test</code> again and when you&rsquo;ve got all green check marks, head on to the next section.</p>

<h3>PUT - Update an Item</h3>

<p>This route will allow requests to update the properties of a single item. We need to make sure that a user is unable to change the <code>id</code> property of the item so that they can&rsquo;t create collisions. To solve this issue, we need to strip out all invalid keys from the submitted payload. But first, a few tests:</p>

<pre><code class="javascript">describe('PUT /api/v1/produce/:id - update an item', () =&gt; {
  it('allows updates to props other than id', () =&gt; {
    return request(app).put('/api/v1/produce/1')
    .send({ quantity: 20 })
    .then((res) =&gt; {
      expect(res.status).toBe(200);
      expect(res.body.message).toBe('Success!');
      expect(res.body.item.quantity).toBe(20);
    });
  });
  it('rejects updates to id prop', () =&gt; {
    return request(app).put('/api/v1/produce/1')
    .send({ id: 10 })
    .then((res) =&gt; {
      expect(res.status).toBe(400);
      expect(res.body.message.startsWith('Update failed')).toBe(true);
    });
  });
});
</code></pre>

<p>Add the new handler to <code>ProduceRouter</code>:</p>

<pre><code class="javascript">/**
 * Update a Produce item by id.
 */
updateOneById(req: $Request, res: $Response): void {
  const searchId: number | boolean = parseId(req.params);
  const payload: any = parseUpdate(req.body);
  let toUpdate: Produce = inventory.find(item =&gt; item.id === searchId);
  if (toUpdate &amp;&amp; payload) {
    Object.keys(payload).forEach((key) =&gt; {
      if (key === 'quantity' || key === 'price') toUpdate[key] = Number(payload[key]);
      else toUpdate[key] = payload[key];
    });
    res.json({
      status: res.status,
      message: 'Success!',
      item: toUpdate
    });
    saveInventory(inventory)
    .then((writePath) =&gt; {
      logger(`Item updated. Inventory written to:\n\t${path.relative(path.join(__dirname, '..', '..'), writePath)}`);
    })
    .catch((err) =&gt; {
      logger('Error writing to inventory file.');
      logger(err.stack);
    });
  } else {
    res.status(400).json({
      status: res.status,
      message: 'Update failed. Make sure the item ID and submitted fields are correct.'
    });
  }
}
</code></pre>

<p>Then, within <em>parsers.js</em>, add the <code>parseId()</code> and <code>parseUpdate()</code> helpers, which are used to clean the payload and requested item ID:</p>

<pre><code class="javascript">export function parseUpdate(input: any): any | null {
  const validKeys = ['name', 'quantity', 'price'];
  const trimmed = Object.keys(input).reduce((obj, curr) =&gt; {
    if (obj &amp;&amp; validKeys.indexOf(curr) !== -1) {
      obj[curr] = input[curr];
      return obj;
    }
  }, {});
  return (trimmed &amp;&amp; Object.keys(trimmed).length &gt; 0) ? trimmed : null;
}

export function parseId(input: any): number | boolean {
  if (input.hasOwnProperty('id'))
    return (typeof input.id === 'string') ? parseInt(input.id, 10) : input.id;
  return false;
}
</code></pre>

<p>These are fairly straightforward. <code>parseUpdate</code> takes in the payload from the request, and strips out any keys that are not <code>name</code>, <code>quantity</code>, or <code>price</code>. Then it just simply returns the trimmed object if there&rsquo;s still keys left, and <code>null</code> if not. <code>parseId</code> is even simpler: It looks for an <code>id</code> property on the payload, converts it to a number (if necessary), and returns.</p>

<p>Update the import in <em>ProduceRouter.js</em>:</p>

<pre><code class="javascript">import { parseProduce, parseUpdate, parseId } from '../util/parsers';
</code></pre>

<p>Then update the <code>init()</code>:</p>

<pre><code class="javascript">/**
 * Attach route handlers to their endpoints.
 */
init(): void {
  this.router.get('/', this.getAll);
  this.router.get('/:id', this.getById);
  this.router.post('/', this.postOne);
  this.router.put('/:id', this.updateOneById);
}
</code></pre>

<p>Run the tests again and ensure they pass. One more route to go!</p>

<h3>DELETE - Remove an Item</h3>

<p>This route will allow for deleting an item from the inventory by passing a valid <code>id</code> as a URL parameter. This is the same string route that the <code>getById</code> and <code>updateOneById</code> functions handle, but will use the <code>DELETE</code> HTTP method. Here&rsquo;s a few basic tests:</p>

<pre><code class="javascript">describe('DELETE /api/v1/produce/:id - delete an item', () =&gt; {
  it('deletes when given a valid ID', () =&gt; {
    return request(app).delete('/api/v1/produce/4')
    .then((res) =&gt; {
      expect(res.status).toBe(200);
      expect(res.body.message).toBe('Success!');
      expect(res.body.deleted.id).toBe(4);
    });
  });
  it('responds w/ error if given invalid ID', () =&gt; {
    return Promise.all([-2, 100].map((id) =&gt; {
      return request(app).delete(`/api/v1/produce/${id}`)
      .then((res) =&gt; {
        expect(res.status).toBe(400);
        expect(res.body.message).toBe('No item found with given ID.');
      });
    }));
  });
});
</code></pre>

<p>Ensure those fail, and then add the implementation for the handler to <code>ProduceRouter</code> as <code>removeById</code>:</p>

<pre><code class="javascript">/**
 * Remove an item from the inventory by ID.
 */
removeById(req: $Request, res: $Response): void {
  const searchId: number | boolean = parseId(req.params);
  let toDel: number = inventory.findIndex(item =&gt; item.id === searchId);
  if (toDel !== -1) {
    let deleted = inventory.splice(toDel, 1)[0];
    res.json({
      status: 200,
      message: 'Success!',
      deleted
    });
    // update json file
    saveInventory(inventory)
    .then((writePath) =&gt; {
      logger(`Item deleted. Inventory written to:\n\t${writePath}`);
    })
    .catch((err) =&gt; {
      logger('Error writing to inventory file.');
      logger(err.stack);
    });
  } else {
    res.status(400).json({
      status: 400,
      message: 'No item found with given ID.'
    });
  }
}
</code></pre>

<p>This obviously looks pretty similar to most of the other handlers. The only difference being that once we get a valid <code>id</code>, we search for the object it matches in the inventory, get its index, and then splice it out of the inventory array.</p>

<p>Don&rsquo;t forget the handler:</p>

<pre><code class="javascript">this.router.delete('/:id', this.removeById);
</code></pre>

<p>Run the tests one last time:</p>

<pre><code class="sh">PASS  __tests__/ProduceRouter.test.js
 Flow API
   ✓ allows updates to props other than id (4ms)
   GET /api/v1/produce - get all produce
     ✓ should return JSON array (50ms)
     ✓ should return objs w/ correct props (11ms)
     ✓ shouldn't return objs w/ extra props (18ms)
   GET /api/v1/produce/:id - get produce item by id
     ✓ should return an obj of type Produce (8ms)
     ✓ should return a Produce w/ requested id (6ms)
     ✓ should 400 on a request for a nonexistant id (9ms)
   POST /api/v1/produce - create new item
     ✓ should accept and add a valid new item (27ms)
     ✓ should reject post w/o name, price, or quantity (9ms)
   PUT /api/v1/produce/:id - update an item
     ✓ allows updates to props other than id (6ms)
     ✓ rejects updates to id prop (7ms)
   DELETE /api/v1/produce/:id - delete an item
     ✓ deletes when given a valid ID (4ms)
     ✓ responds w/ error if given invalid ID (11ms)

Test Suites: 1 passed, 1 total
Tests:       13 passed, 13 total
Snapshots:   0 total
Time:        2.322s
Ran all test suites.
</code></pre>

<p>Congratulations! You just built an Express API type checked with Flow!</p>

<h2>Conclusion</h2>

<p>All in all, working with Flow is interesting, at the very least.</p>

<p>After using both it and TypeScript, Flow&rsquo;s type checking tends to be more strict, but you also spend more time trying to figure out what Flow is getting at and how to fix errors. Part of this is probably that the tooling support for TypeScript is vastly superior. Flow offers a lot of the same functionality that TypeScript does, but there&rsquo;s a TypeScript tool for every single thing you could ever want. It simply isn&rsquo;t the same for Flow. The community doesn&rsquo;t seem to have embraced it with as much enthusiasm. The number of libdefs in the <code>flow-typed</code> repository versus <code>DefinitelyTyped</code> for TypeScript is tiny. This is probably the biggest problem you&rsquo;d have to face in choosing to use Flow for static type analysis over TypeScript.</p>

<p>That being said, Flow also offers some distinct advantages.</p>

<p>It&rsquo;s plug-n-play with Babel, so adding Flow to a project using Babel would probably be much less painful than converting it to use TypeScript. Both allow you to do so bit by bit, but Flow handles this more gracefully. TypeScript would usually like to just have you pass everything through the compiler and deal with the type errors as you can. Flow allows you to annotate <em>only</em> the files you want to type check, so adding it to an existing project is much easier. Actually, this is probably the best use case for Flow. It would be cumbersome to start a brand new project with such strict type checking. It definitely slows down the rapid iteration needed at the beginning of a project&rsquo;s life. However, once the project gets to a certain size it&rsquo;s easy to drop in Flow and clean up the errors file by file as you move forward.</p>

<p>You can grab the code from the <a href="https://github.com/mjhea0/flow-node-api">flow-node-api</a> repo. Best!</p>
]]></content>
  </entry>
  
</feed>
